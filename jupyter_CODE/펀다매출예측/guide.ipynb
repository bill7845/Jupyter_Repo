{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 기본\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# 시계열\n",
    "# from fbprophet import Prophet\n",
    "from datetime import datetime as dt\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing, Holt, ExponentialSmoothing\n",
    "\n",
    "# 회귀분석\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "\n",
    "# Deep Neural Network\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "import time\n",
    "\n",
    "# 설정\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(mae)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가산식\n",
    "\n",
    "def mae(prediction, correct):\n",
    "    prediction = np.array(prediction)\n",
    "    correct = np.array(correct)\n",
    "    \n",
    "    difference = correct - prediction\n",
    "    abs_val = abs(difference)\n",
    "    \n",
    "    score = abs_val.mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "mae_scorer = make_scorer(mae)\n",
    "mae_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6556613, 8)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('C:/Users/KIHyuk/Desktop/dacon_data/Data_펀다/funda_train.csv')\n",
    "df_sub = pd.read_csv('C:/Users/KIHyuk/Desktop/dacon_data/Data_펀다/submission.csv')\n",
    "df_train['transacted_date'] = pd.to_datetime(df_train['transacted_date']) # time column\n",
    "df_train = df_train.set_index('transacted_date')\n",
    "\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_day(train_df): \n",
    "    df_day = pd.DataFrame() \n",
    "    for i in train_df.store_id.unique(): # each unique store_id \n",
    "        df_num = train_df[train_df.store_id == i] # store_id별로 적용하기 위해\n",
    "        \n",
    "        # 'card_id' 의 일별 counting을 통해 일 거래 횟수 확인\n",
    "        count_cols = df_num['card_id'].resample(rule='d').count().rename('num_of_pay')\n",
    "        \n",
    "        # 'card_id' value count가 2보다 크면 단골인 것으로 판단하고 단골 방문 횟수 확인\n",
    "        # 1. store_id 별 card_id에서 value_counts() 실행 => card_id를 index로 가지고 count를 값으로 반환\n",
    "        # 2. count가 2이상인 단골 card_id만 추출하기 위해 reset_index 실행 => count가 2이상인 card_id의 index로 reset_index\n",
    "        revisit_idx = df_num.card_id.value_counts().reset_index().query(\"card_id > 2\")[\"index\"].values # 단골 card_id\n",
    "        # store_id 별 단골 card_id를 알아내었다.\n",
    "        # 해당 card_id들을 일별로 count resampling 해주어서 일별 단골들의 결제 횟수를 추출\n",
    "        revisit_ct = df_num[df_num.card_id.isin(revisit_idx)].card_id.resample(rule='d').count().rename('num_of_revisit')\n",
    "        \n",
    "        # 할부 개월수와 매출액은 일 단위로 합\n",
    "        # store_id 별 일단위 할부개월수/매출액\n",
    "        sum_cols = df_num[['installment_term', 'amount']].resample(rule='d').sum()\n",
    "        \n",
    "        # 일별 총거래횟수/ 일별 단골거래횟수 / 일별 매출액 /일별 할부개월수\n",
    "        df_num_day = pd.concat([count_cols, revisit_ct, sum_cols], axis=1)\n",
    "\n",
    "        df_num_day.insert(0, 'store_id', i) # store_id 컬럼 추가\n",
    "        df_num_day.insert(4, 'region', df_num[df_num.store_id == i].region.unique()[0]) # 지역 추가\n",
    "        df_num_day.insert(5, 'type_of_business', df_num[df_num.store_id == i].type_of_business.unique()[0]) # 업종 추가\n",
    "\n",
    "        df_day = pd.concat([df_day, df_num_day], axis=0) # stored_id별로 위 작업을 누적하여 concat하기 위해\n",
    "        \n",
    "    df_day.insert(1, 'day_of_week', df_day.index.dayofweek) # index에 맞추어 몇번째 주인가 \n",
    "    df_day.insert(2, 'business_day', df_day.day_of_week.replace({0:1, 2:1, 3:1, 4:1, 5:0, 6:0}).values) # 평일 1, 주말 0\n",
    "    df_day.num_of_revisit.fillna(0, inplace=True) \n",
    "    \n",
    "    return df_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_day = resample_day(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day.to_csv('funda_train_day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day = pd.read_csv('funda_train_day.csv')\n",
    "df_day['transacted_date'] = pd.to_datetime(df_day['transacted_date'])\n",
    "df_day = df_day.set_index('transacted_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관관계 확인\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 7)\n",
    "sns.heatmap(daily_corr, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_month(frame_day):\n",
    "    sum_cols = ['num_of_pay', 'num_of_revisit', 'installment_term', 'amount']\n",
    "\n",
    "    df_monthly = pd.DataFrame()\n",
    "\n",
    "    for i in frame_day.store_id.unique():\n",
    "        df_set = frame_day[frame_day.store_id == i]\n",
    "        \n",
    "        # nan값이 발생하는 경우를 없애기 위해 이전, 이후 달에 대한 정보를 추가한 후 제거\n",
    "        prev_date = pd.date_range(start=(df_set.index[0] - relativedelta(months=1)), end=(df_set.index[0] - relativedelta(months=1)))\n",
    "        add_date = pd.date_range(start=(df_set.index[-1] + relativedelta(months=1)), end=(df_set.index[-1] + relativedelta(months=1)))\n",
    "        df_set = pd.concat([pd.DataFrame(index=prev_date), df_set, pd.DataFrame(index=add_date)], axis=0)\n",
    "\n",
    "        df_set.loc[dt.strftime(df_set.index[0], '%Y-%m'), :] = 1\n",
    "        df_set.loc[dt.strftime(df_set.index[-1], '%Y-%m'), :] = 1\n",
    "\n",
    "        tot_day = df_set[df_set.amount != 0].day_of_week.resample(rule='m').count().rename('real_tot_day')\n",
    "        business = df_set[df_set.amount != 0].business_day.resample(rule='m').sum().rename('real_business_day')\n",
    "\n",
    "        business = business.drop([business.index[0], business.index[-1]], axis=0)\n",
    "        tot_day = tot_day.drop([tot_day.index[0], tot_day.index[-1]], axis=0)\n",
    "        df_set = df_set.drop([df_set.index[0], df_set.index[-1]], axis=0)\n",
    "\n",
    "        df = pd.concat([tot_day, business, df_set[sum_cols].resample(rule='m').sum()], axis=1)\n",
    "\n",
    "        df.insert(0, 'store_id', i)\n",
    "        df.insert(6, 'region', df_set.region.values[0])\n",
    "        df.insert(7, 'type_of_business', df_set.type_of_business.values[0])\n",
    "\n",
    "        df_monthly = pd.concat([df_monthly, df], axis=0)\n",
    "   \n",
    "    return df_monthly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
