{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 기본\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# 시계열\n",
    "# from fbprophet import Prophet\n",
    "from datetime import datetime as dt\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing, Holt, ExponentialSmoothing\n",
    "\n",
    "# 회귀분석\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "\n",
    "# Deep Neural Network\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "import time\n",
    "\n",
    "# 설정\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(mae)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가산식\n",
    "\n",
    "def mae(prediction, correct):\n",
    "    prediction = np.array(prediction)\n",
    "    correct = np.array(correct)\n",
    "    \n",
    "    difference = correct - prediction\n",
    "    abs_val = abs(difference)\n",
    "    \n",
    "    score = abs_val.mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "mae_scorer = make_scorer(mae)\n",
    "mae_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6556613, 8)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('C:/Users/KIHyuk/Desktop/dacon_data/Data_펀다/funda_train.csv')\n",
    "df_sub = pd.read_csv('C:/Users/KIHyuk/Desktop/dacon_data/Data_펀다/submission.csv')\n",
    "df_train['transacted_date'] = pd.to_datetime(df_train['transacted_date']) # time column\n",
    "df_train = df_train.set_index('transacted_date')\n",
    "\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df_train[df_train.store_id == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisit_idx = df_num.card_id.value_counts().reset_index().query(\"card_id > 2\")[\"index\"].values\n",
    "revisit_ct = df_num[df_num.card_id.isin(revisit_idx)].card_id.resample(rule='d').count().rename('num_of_visit')\n",
    "count_cols = df_num['card_id'].resample('d').count().rename('num_of_pay')\n",
    "sum_cols = df_num[['installment_term', 'amount']].resample(rule='d').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_day = pd.concat([count_cols,revisit_ct,sum_cols],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_day.insert(0, 'store_id', 1) # store_id 컬럼 추가\n",
    "df_num_day.insert(4, 'region', df_num[df_num.store_id == 1].region.unique()[0]) # 지역 추가\n",
    "df_num_day.insert(5, 'type_of_business', df_num[df_num.store_id == 1].type_of_business.unique()[0]) # 업종 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day = pd.concat([df_day,df_num_day],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day.insert(1, 'day_of_week', df_day.index.dayofweek)\n",
    "df_day.insert(2, 'business_day', df_day.day_of_week.replace({0:1, 2:1, 3:1, 4:1, 5:0, 6:0}).values) # 평일 1, 주말 0\n",
    "df_day.num_of_visit.fillna(0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>business_day</th>\n",
       "      <th>num_of_pay</th>\n",
       "      <th>num_of_visit</th>\n",
       "      <th>installment_term</th>\n",
       "      <th>region</th>\n",
       "      <th>type_of_business</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transacted_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8357.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-06-03</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-06-04</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-06-05</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-02-25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3928.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5785.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-02-27</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6071.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-02-28</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1003 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 store_id  day_of_week  business_day  num_of_pay  \\\n",
       "transacted_date                                                    \n",
       "2016-06-01              1            2             1           6   \n",
       "2016-06-02              1            3             1           8   \n",
       "2016-06-03              1            4             1           4   \n",
       "2016-06-04              1            5             0           0   \n",
       "2016-06-05              1            6             0           0   \n",
       "...                   ...          ...           ...         ...   \n",
       "2019-02-24              1            6             0           0   \n",
       "2019-02-25              1            0             1           7   \n",
       "2019-02-26              1            1             1           6   \n",
       "2019-02-27              1            2             1           7   \n",
       "2019-02-28              1            3             1           4   \n",
       "\n",
       "                 num_of_visit  installment_term  region  type_of_business  \\\n",
       "transacted_date                                                             \n",
       "2016-06-01                  5                 0     NaN               NaN   \n",
       "2016-06-02                  6                 0     NaN               NaN   \n",
       "2016-06-03                  2                 0     NaN               NaN   \n",
       "2016-06-04                  0                 0     NaN               NaN   \n",
       "2016-06-05                  0                 0     NaN               NaN   \n",
       "...                       ...               ...     ...               ...   \n",
       "2019-02-24                  0                 0     NaN               NaN   \n",
       "2019-02-25                  6                 0     NaN               NaN   \n",
       "2019-02-26                  2                 0     NaN               NaN   \n",
       "2019-02-27                  6                 0     NaN               NaN   \n",
       "2019-02-28                  3                 0     NaN               NaN   \n",
       "\n",
       "                      amount  \n",
       "transacted_date               \n",
       "2016-06-01       6500.000000  \n",
       "2016-06-02       8357.142857  \n",
       "2016-06-03       5500.000000  \n",
       "2016-06-04          0.000000  \n",
       "2016-06-05          0.000000  \n",
       "...                      ...  \n",
       "2019-02-24          0.000000  \n",
       "2019-02-25       3928.571429  \n",
       "2019-02-26       5785.714286  \n",
       "2019-02-27       6071.428571  \n",
       "2019-02-28       3000.000000  \n",
       "\n",
       "[1003 rows x 9 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_day(train_df):\n",
    "    df_day = pd.DataFrame() \n",
    "    for i in train_df.store_id.unique(): # each unique store_id \n",
    "        df_num = train_df[train_df.store_id == i] # store_id별로 적용하기 위해\n",
    "        \n",
    "        # 'card_id' 의 일별 counting을 통해 일 거래 횟수 확인\n",
    "        count_cols = df_num['card_id'].resample(rule='d').count().rename('num_of_pay')\n",
    "        \n",
    "        # 'card_id' value count가 2보다 크면 단골인 것으로 판단하고 단골 방문 횟수 확인\n",
    "        # 1. store_id 별 card_id에서 value_counts() 실행 => card_id를 index로 가지고 count를 값으로 반환\n",
    "        # 2. count가 2이상인 단골 card_id만 추출하기 위해 reset_index 실행 => count가 2이상인 card_id의 index로 reset_index\n",
    "        revisit_idx = df_num.card_id.value_counts().reset_index().query(\"card_id > 2\")[\"index\"].values # 단골 card_id\n",
    "        # store_id 별 단골 card_id를 알아내었다.\n",
    "        # 해당 card_id들을 일별로 count resampling 해주어서 일별 단골들의 결제 횟수를 추출\n",
    "        revisit_ct = df_num[df_num.card_id.isin(revisit_idx)].card_id.resample(rule='d').count().rename('num_of_revisit')\n",
    "        \n",
    "        # 할부 개월수와 매출액은 일 단위로 합\n",
    "        # store_id 별 일단위 할부개월수/매출액\n",
    "        sum_cols = df_num[['installment_term', 'amount']].resample(rule='d').sum()\n",
    "        \n",
    "        # 일별 총거래횟수/ 일별 단골거래횟수 / 일별 매출액 /일별 할부개월수\n",
    "        df_num_day = pd.concat([count_cols, revisit_ct, sum_cols], axis=1)\n",
    "\n",
    "        df_num_day.insert(0, 'store_id', i) # store_id 컬럼 추가\n",
    "        df_num_day.insert(4, 'region', df_num[df_num.store_id == i].region.unique()[0]) # 지역 추가\n",
    "        df_num_day.insert(5, 'type_of_business', df_num[df_num.store_id == i].type_of_business.unique()[0]) # 업종 추가\n",
    "\n",
    "        df_day = pd.concat([df_day, df_num_day], axis=0) # stored_id별로 위 작업을 누적하여 concat하기 위해\n",
    "        \n",
    "    df_day.insert(1, 'day_of_week', df_day.index.dayofweek)\n",
    "    df_day.insert(2, 'business_day', df_day.day_of_week.replace({0:1, 2:1, 3:1, 4:1, 5:0, 6:0}).values) # 평일 1, 주말 0\n",
    "    df_day.num_of_revisit.fillna(0, inplace=True) \n",
    "    \n",
    "    return df_day"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
