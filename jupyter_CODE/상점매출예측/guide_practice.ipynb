{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import math\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import scipy.stats as st\n",
    "from datetime import datetime, timedelta\n",
    "warnings.filterwarnings(\"ignore\")  # specify to ignore warning messages\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "test = pd.read_csv('C:/Users/KIHyuk/Desktop/dacon_data/Data_상점매출/test.csv')\n",
    "submission = pd.read_csv('C:/Users/KIHyuk/Desktop/dacon_data/Data_상점매출/submission.csv')\n",
    "\n",
    "df_copy = test.copy() # 복사본\n",
    "df_copy['date'] = pd.to_datetime(df_copy.date)\n",
    "\n",
    "df_copy['date'] = pd.to_datetime(df_copy.date.astype(str) + \" \" + df_copy.time, format='%Y-%m-%d %H:%M:%S') # date + time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>card_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>installments</th>\n",
       "      <th>days_of_week</th>\n",
       "      <th>holyday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-01 00:28:15</td>\n",
       "      <td>00:28:15</td>\n",
       "      <td>bf33518373</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-01 01:09:58</td>\n",
       "      <td>01:09:58</td>\n",
       "      <td>7a19a3a92f</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-01 01:47:24</td>\n",
       "      <td>01:47:24</td>\n",
       "      <td>6f9fd7e241</td>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-01 17:54:43</td>\n",
       "      <td>17:54:43</td>\n",
       "      <td>8bcf1d61b2</td>\n",
       "      <td>362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-01 18:48:53</td>\n",
       "      <td>18:48:53</td>\n",
       "      <td>6a722ce674</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473387</td>\n",
       "      <td>199</td>\n",
       "      <td>2018-03-30 14:17:59</td>\n",
       "      <td>14:17:59</td>\n",
       "      <td>300d7bc922</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473388</td>\n",
       "      <td>199</td>\n",
       "      <td>2018-03-30 19:01:54</td>\n",
       "      <td>19:01:54</td>\n",
       "      <td>3ab757718b</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473389</td>\n",
       "      <td>199</td>\n",
       "      <td>2018-03-30 20:08:03</td>\n",
       "      <td>20:08:03</td>\n",
       "      <td>2d8e9e421c</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473390</td>\n",
       "      <td>199</td>\n",
       "      <td>2018-03-30 20:11:58</td>\n",
       "      <td>20:11:58</td>\n",
       "      <td>22daeb334e</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473391</td>\n",
       "      <td>199</td>\n",
       "      <td>2018-03-31 11:41:18</td>\n",
       "      <td>11:41:18</td>\n",
       "      <td>2e698f3302</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>473392 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        store_id                date      time     card_id  amount  \\\n",
       "0              0 2016-08-01 00:28:15  00:28:15  bf33518373     125   \n",
       "1              0 2016-08-01 01:09:58  01:09:58  7a19a3a92f      90   \n",
       "2              0 2016-08-01 01:47:24  01:47:24  6f9fd7e241     150   \n",
       "3              0 2016-08-01 17:54:43  17:54:43  8bcf1d61b2     362   \n",
       "4              0 2016-08-01 18:48:53  18:48:53  6a722ce674     125   \n",
       "...          ...                 ...       ...         ...     ...   \n",
       "473387       199 2018-03-30 14:17:59  14:17:59  300d7bc922      65   \n",
       "473388       199 2018-03-30 19:01:54  19:01:54  3ab757718b      65   \n",
       "473389       199 2018-03-30 20:08:03  20:08:03  2d8e9e421c      65   \n",
       "473390       199 2018-03-30 20:11:58  20:11:58  22daeb334e     200   \n",
       "473391       199 2018-03-31 11:41:18  11:41:18  2e698f3302     500   \n",
       "\n",
       "        installments  days_of_week  holyday  \n",
       "0                NaN             0        0  \n",
       "1                NaN             0        0  \n",
       "2                NaN             0        0  \n",
       "3                NaN             0        0  \n",
       "4                NaN             0        0  \n",
       "...              ...           ...      ...  \n",
       "473387           NaN             4        0  \n",
       "473388           NaN             4        0  \n",
       "473389           NaN             4        0  \n",
       "473390           NaN             4        0  \n",
       "473391           NaN             5        0  \n",
       "\n",
       "[473392 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove negative values from the data set.\n",
    "# 하루 매출이 음수가 되는 경우 존재.\n",
    "\n",
    "def reduce_noise_by_removing_neg_vals(df_copy):\n",
    "    df_pos = df_copy[df_copy['amount'] > 0] # 정상거래\n",
    "    df_neg = df_copy[df_copy['amount'] < 0] # 거래취소\n",
    "\n",
    "#     start = datetime.now() # 현재시간\n",
    "\n",
    "    for nega_i in df_neg.to_records()[:]: # to_records : DataFrame => ndarray\n",
    "        store_i = nega_i[1]  # i번째 행의 store_id  # -거래\n",
    "        date_i = nega_i[2] # i번째 행의 date  # -거래\n",
    "        card_i = nega_i[4] # i번째 행의 card_id  # -거래\n",
    "        amt_i = nega_i[5] # i번째 행의 amount  # -거래\n",
    "        row_i = df_pos[df_pos['store_id'] == store_i] # 정상거래 중 store_id가 i번째(-거래) store_i와 같은 데이터 추출\n",
    "        row_i = row_i[row_i['card_id'] == card_i] # 정상거래 중 card_id가 i번째(-거래) card_id와 같은 데이터 추출\n",
    "        row_i = row_i[row_i['amount'] >= abs(amt_i)] # -거래와 절대값이 같거나 큰 결제정보 중\n",
    "        row_i = row_i[row_i['date'] <= date_i] # -거래 이전데이터 중 \n",
    "        if len(row_i[row_i['amount'] == abs(amt_i)]) > 0: # -거래 이전 거래중 절대값이 같은 거래가 있다면,,\n",
    "            row_i = row_i[row_i['amount'] == abs(amt_i)] # 여기 왜 필요?..\n",
    "            matched_row = row_i[row_i['date'] == max(row_i['date'])] # 가장 최근 시점 \n",
    "            # df_pos.loc[matched_row.index, 'amount'] = 0\n",
    "            df_pos = df_pos.loc[~df_pos.index.isin(matched_row.index), :] # matched_row에 해당하는 거래정보 제거(index이용)\n",
    "        elif len(row_i[row_i['amount'] > abs(amt_i)]) > 0: # -거래 이전 거래중 절대값이 더 큰 거래가 있다면,,\n",
    "            matched_row = row_i[row_i.date == max(row_i.date)]\n",
    "            df_pos.loc[matched_row.index, 'amount'] = matched_row.amount + amt_i # 차액만큼만\n",
    "        # else:\n",
    "        #     pass\n",
    "            # no_match.append(nega_i)\n",
    "#     end = datetime.now()\n",
    "#     time_took = (end - start).seconds / 60\n",
    "\n",
    "#     print(round(time_took, 2))\n",
    "    return df_pos # df_pos는 -거래 없는 데이터(-거래에 따른 환불처리까지)\n",
    "\n",
    "df_pos = reduce_noise_by_removing_neg_vals(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(y): # stationary test function\n",
    "    # perform Augmented Dickey Fuller test\n",
    "    print('Results of Augmented Dickey-Fuller test:')\n",
    "    dftest = adfuller(y, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['test statistic', 'p-value', '# of lags', '# of observations'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value ({})'.format(key)] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_diagnostics(y, lags=None, title='', filename=''):\n",
    "    '''\n",
    "    Calculate acf, pacf, qq plot and Augmented Dickey Fuller test for a given time series\n",
    "    '''\n",
    "    if not isinstance(y, pd.Series): # y의 type이 Series가 아니라면\n",
    "        y = pd.Series(y) # Series로 변경\n",
    "\n",
    "    # weekly moving averages (5 day window because of workdays)\n",
    "    rolling_mean = pd.Series.rolling(y, window=2).mean() # y.rolling(2).mean()\n",
    "    rolling_std = pd.Series.rolling(y, window=2).std()\n",
    "\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    layout = (3, 2)\n",
    "    ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n",
    "    acf_ax = plt.subplot2grid(layout, (1, 0))\n",
    "    pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "    qq_ax = plt.subplot2grid(layout, (2, 0))\n",
    "    hist_ax = plt.subplot2grid(layout, (2, 1))\n",
    "\n",
    "    # time series plot\n",
    "    y.plot(ax=ts_ax)\n",
    "    rolling_mean.plot(ax=ts_ax, color='crimson')\n",
    "    rolling_std.plot(ax=ts_ax, color='darkslateblue')\n",
    "    plt.legend(loc='best')\n",
    "    ts_ax.set_title(title, fontsize=24)\n",
    "\n",
    "    # acf and pacf\n",
    "    plot_acf(y, lags=lags, ax=acf_ax, alpha=0.5)\n",
    "    plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.5)\n",
    "\n",
    "    # qq plot\n",
    "    sm.qqplot(y, line='s', ax=qq_ax)\n",
    "    qq_ax.set_title('QQ Plot')\n",
    "\n",
    "    # hist plot\n",
    "    y.plot(ax=hist_ax, kind='hist', bins=25)\n",
    "    hist_ax.set_title('Histogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # perform Augmented Dickey Fuller test\n",
    "    print('Results of Dickey-Fuller test:')\n",
    "    dftest = adfuller(y, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['test statistic', 'p-value', '# of lags', '# of observations'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)' % key] = value\n",
    "    print(dfoutput)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 굳이 해야되는 코드인가..\n",
    "df = df_pos.copy()\n",
    "test_groupby_date_store = df.groupby(['date', 'store_id'])['amount', 'holyday'].sum() # time,store_id 별 매출,휴무일수 합산\n",
    "\n",
    "test_groupby_date_store = test_groupby_date_store.reset_index() # store_id를 다시 col로 만들기 위해\n",
    "test_groupby_date_store = test_groupby_date_store.set_index('date') # store_id 다시 col되어 있음\n",
    "\n",
    "store_list = test_groupby_date_store.store_id.unique()\n",
    "\n",
    "store_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9580957780787686\n",
      "1.7290036387221377\n"
     ]
    }
   ],
   "source": [
    "def get_optimal_params(y): # ARIMA의 최적 p,d,q \n",
    "    # Define the p, d and q parameters to take any value between 0 and 1\n",
    "\n",
    "    param_dict = {}\n",
    "    for param in pdq:\n",
    "        try:\n",
    "            # model_1 => SARIMAX\n",
    "            mod = sm.tsa.statespace.SARIMAX(y,\n",
    "                                            order=param, # pdq\n",
    "                                            )\n",
    "            results = mod.fit()\n",
    "            \n",
    "            # model_2 => ARIMA\n",
    "            model = ARIMA(y, order=param)\n",
    "            \n",
    "            results_ARIMA = model.fit(disp=-1) # disp=-1 => not error message \n",
    "            results_ARIMA.summary()\n",
    "            \n",
    "            param_dict[results.aic] = param # result.aic의 param  # 해당 aic가 나오도록 한 param을 알기위해\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    min_aic = min(param_dict.keys()) # aic중 최소값\n",
    "    optimal_params = param_dict[min_aic]\n",
    "    return optimal_params # aic를 최소로하는 param return\n",
    "\n",
    "###############################################################################################################\n",
    "sampling_p = 28\n",
    "mean_period = 2 * 3 #14 * 2*3\n",
    "\n",
    "predic_len = math.floor(100 / sampling_p)\n",
    "\n",
    "expected_return_pct_lending = 0.13 * (100 + 16 + 6.8) / 365\n",
    "expected_loss_pct_lending = 1.00\n",
    "optimal_prob = expected_loss_pct_lending / (expected_loss_pct_lending + expected_return_pct_lending)\n",
    "optimal_z_score = st.norm.ppf(optimal_prob)\n",
    "\n",
    "min_period = 6\n",
    "###############################################################################################################\n",
    "\n",
    "\n",
    "max_pdq = 2\n",
    "p = d = q = range(0, max_pdq)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "\n",
    "pdqs = dict()\n",
    "print(optimal_prob)\n",
    "print(optimal_z_score)\n",
    "output_file_name_fmt = '../1st_data/py_4arima_pos_sep_{optimal_p}-{sampling_period}_no_sales_prob&no mean{mean_period}&min_period {min_period}_pdq{max_pdq}.csv'\n",
    "output_file_name = output_file_name_fmt.format(optimal_p=round(optimal_prob, 4),\n",
    "                                               sampling_period=sampling_p,\n",
    "                                               mean_period=mean_period,\n",
    "                                               min_period=min_period,\n",
    "                                               max_pdq=max_pdq)\n",
    "\n",
    "submission_copy = submission.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_main(input_df, sampling_period_days, fcst_period):\n",
    "    input_df = input_df[len(input_df) % sampling_period_days:].resample(str(sampling_period_days) + 'D').sum()\n",
    "    prob_of_no_sales = len(input_df[(input_df.amount == 0) | (input_df.amount.isna())]) / len(input_df)\n",
    "    ts_log = np.log(input_df.amount)\n",
    "    ts_log = ts_log[~ts_log.isin([np.nan, np.inf, -np.inf])] # log를 씌운 amount중 nan,무한대값을 제거\n",
    "\n",
    "    if len(ts_log) < min_period:\n",
    "        return None\n",
    "    if sampling_period_days >= 28:\n",
    "        expected_return_pct_lending = 0.13 * (100 + 16 + 6.8) / 365\n",
    "    elif sampling_period_days >= 14:\n",
    "        expected_return_pct_lending = 0.13 * (100 + 16 + 14) / 365\n",
    "    else:\n",
    "        expected_return_pct_lending = 0.13 * (100 + 16 + 6.8) / 365\n",
    "\n",
    "    expected_loss_pct_lending = 1.00\n",
    "    optimal_prob = expected_loss_pct_lending / (expected_loss_pct_lending + expected_return_pct_lending)\n",
    "    optimal_z_score = st.norm.ppf(optimal_prob)\n",
    "\n",
    "    optimal_params = get_optimal_params(ts_log) # optimal param\n",
    "    pdqs[store_i] = optimal_params\n",
    "\n",
    "    # ARIMA model\n",
    "    model = ARIMA(ts_log, order=optimal_params)\n",
    "    results_ARIMA = model.fit(disp=-1)\n",
    "    fcst = results_ARIMA.forecast(fcst_period)\n",
    "\n",
    "    fcst_means = fcst[0]\n",
    "    fcst_stds = fcst[1]\n",
    "    fcst_i = fcst_means - (fcst_stds * optimal_z_score)\n",
    "    fcst_i = sum(map(lambda x: np.exp(x) if np.exp(x) > 0 else 0, fcst_i))\n",
    "    prediction_i = fcst_i * (1 - prob_of_no_sales)\n",
    "    return prediction_i\n",
    "\n",
    "##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../1st_data/py_4arima_pos_sep_0.9581-28_no_sales_prob&no mean6&min_period 6_pdq2.csv\n"
     ]
    }
   ],
   "source": [
    "for store_i in store_list[:]:\n",
    "    prediction_i = None\n",
    "    test_df = test_groupby_date_store[test_groupby_date_store.store_id == store_i]\n",
    "    test_df_daily = test_df.resample('D').sum()\n",
    "    prediction_i = arima_main(test_df_daily, sampling_period_days=28, fcst_period=3)\n",
    "    # if prediction_i is None:\n",
    "    #     prediction_i = arima_main(test_df_daily, sampling_period_days=21, fcst_period=4)\n",
    "    if prediction_i is None:\n",
    "        prediction_i = arima_main(test_df_daily, sampling_period_days=14, fcst_period=7)\n",
    "    if prediction_i is None:\n",
    "        prediction_i = arima_main(test_df_daily, sampling_period_days=7, fcst_period=12)\n",
    "    if prediction_i is None:\n",
    "        test_df = test_df_daily[len(test_df_daily) % 14:].resample('14D').sum()\n",
    "\n",
    "        prob_of_no_sales = len(test_df[(test_df.amount == 0) | (test_df.amount.isna())]) / len(test_df)\n",
    "        ts_log = ts_log[~ts_log.isin([np.nan, np.inf, -np.inf])]\n",
    "        ts_log_wkly = np.log(test_df.amount)\n",
    "\n",
    "        estimated_amt = np.exp(ts_log_wkly.mean() - ts_log_wkly.std() * optimal_z_score) * (1 - prob_of_no_sales)\n",
    "        prediction_i = estimated_amt * mean_period\n",
    "\n",
    "    submission_copy.loc[submission_copy['store_id'] == store_i, 'total_sales'] = prediction_i\n",
    "\n",
    "# submission_copy.to_csv(output_file_name, index=False)\n",
    "\n",
    "print(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68426.936910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11840.490783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16208.571184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26870.446220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11752.421019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>31237.923574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>196</td>\n",
       "      <td>31340.097798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>57.921562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>1061.787577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>18906.142306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     store_id   total_sales\n",
       "0           0  68426.936910\n",
       "1           1  11840.490783\n",
       "2           2  16208.571184\n",
       "3           3  26870.446220\n",
       "4           4  11752.421019\n",
       "..        ...           ...\n",
       "195       195  31237.923574\n",
       "196       196  31340.097798\n",
       "197       197     57.921562\n",
       "198       198   1061.787577\n",
       "199       199  18906.142306\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_copy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
