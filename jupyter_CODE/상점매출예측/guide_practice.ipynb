{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import math\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import scipy.stats as st\n",
    "from datetime import datetime, timedelta\n",
    "warnings.filterwarnings(\"ignore\")  # specify to ignore warning messages\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "test = pd.read_csv('C:/Users/KIHyuk/Desktop/dacon_data/Data_상점매출/test.csv')\n",
    "submission = pd.read_csv('C:/Users/KIHyuk/Desktop/dacon_data/Data_상점매출/submission.csv')\n",
    "\n",
    "df_copy = test.copy() # 복사본\n",
    "df_copy['date'] = pd.to_datetime(df_copy.date)\n",
    "\n",
    "df_copy['date'] = pd.to_datetime(df_copy.date.astype(str) + \" \" + df_copy.time, format='%Y-%m-%d %H:%M:%S') # date + time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>card_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>installments</th>\n",
       "      <th>days_of_week</th>\n",
       "      <th>holyday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-01 00:28:15</td>\n",
       "      <td>00:28:15</td>\n",
       "      <td>bf33518373</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-01 01:09:58</td>\n",
       "      <td>01:09:58</td>\n",
       "      <td>7a19a3a92f</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-01 01:47:24</td>\n",
       "      <td>01:47:24</td>\n",
       "      <td>6f9fd7e241</td>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-01 17:54:43</td>\n",
       "      <td>17:54:43</td>\n",
       "      <td>8bcf1d61b2</td>\n",
       "      <td>362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-01 18:48:53</td>\n",
       "      <td>18:48:53</td>\n",
       "      <td>6a722ce674</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473387</td>\n",
       "      <td>199</td>\n",
       "      <td>2018-03-30 14:17:59</td>\n",
       "      <td>14:17:59</td>\n",
       "      <td>300d7bc922</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473388</td>\n",
       "      <td>199</td>\n",
       "      <td>2018-03-30 19:01:54</td>\n",
       "      <td>19:01:54</td>\n",
       "      <td>3ab757718b</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473389</td>\n",
       "      <td>199</td>\n",
       "      <td>2018-03-30 20:08:03</td>\n",
       "      <td>20:08:03</td>\n",
       "      <td>2d8e9e421c</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473390</td>\n",
       "      <td>199</td>\n",
       "      <td>2018-03-30 20:11:58</td>\n",
       "      <td>20:11:58</td>\n",
       "      <td>22daeb334e</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473391</td>\n",
       "      <td>199</td>\n",
       "      <td>2018-03-31 11:41:18</td>\n",
       "      <td>11:41:18</td>\n",
       "      <td>2e698f3302</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>473392 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        store_id                date      time     card_id  amount  \\\n",
       "0              0 2016-08-01 00:28:15  00:28:15  bf33518373     125   \n",
       "1              0 2016-08-01 01:09:58  01:09:58  7a19a3a92f      90   \n",
       "2              0 2016-08-01 01:47:24  01:47:24  6f9fd7e241     150   \n",
       "3              0 2016-08-01 17:54:43  17:54:43  8bcf1d61b2     362   \n",
       "4              0 2016-08-01 18:48:53  18:48:53  6a722ce674     125   \n",
       "...          ...                 ...       ...         ...     ...   \n",
       "473387       199 2018-03-30 14:17:59  14:17:59  300d7bc922      65   \n",
       "473388       199 2018-03-30 19:01:54  19:01:54  3ab757718b      65   \n",
       "473389       199 2018-03-30 20:08:03  20:08:03  2d8e9e421c      65   \n",
       "473390       199 2018-03-30 20:11:58  20:11:58  22daeb334e     200   \n",
       "473391       199 2018-03-31 11:41:18  11:41:18  2e698f3302     500   \n",
       "\n",
       "        installments  days_of_week  holyday  \n",
       "0                NaN             0        0  \n",
       "1                NaN             0        0  \n",
       "2                NaN             0        0  \n",
       "3                NaN             0        0  \n",
       "4                NaN             0        0  \n",
       "...              ...           ...      ...  \n",
       "473387           NaN             4        0  \n",
       "473388           NaN             4        0  \n",
       "473389           NaN             4        0  \n",
       "473390           NaN             4        0  \n",
       "473391           NaN             5        0  \n",
       "\n",
       "[473392 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove negative values from the data set.\n",
    "# 하루 매출이 음수가 되는 경우 존재.\n",
    "\n",
    "def reduce_noise_by_removing_neg_vals(df_copy):\n",
    "    df_pos = df_copy[df_copy['amount'] > 0] # 정상거래\n",
    "    df_neg = df_copy[df_copy['amount'] < 0] # 거래취소\n",
    "\n",
    "#     start = datetime.now() # 현재시간\n",
    "\n",
    "    for nega_i in df_neg.to_records()[:]: # to_records : DataFrame => ndarray\n",
    "        store_i = nega_i[1]  # i번째 행의 store_id  # -거래\n",
    "        date_i = nega_i[2] # i번째 행의 date  # -거래\n",
    "        card_i = nega_i[4] # i번째 행의 card_id  # -거래\n",
    "        amt_i = nega_i[5] # i번째 행의 amount  # -거래\n",
    "        row_i = df_pos[df_pos['store_id'] == store_i] # 정상거래 중 store_id가 i번째(-거래) store_i와 같은 데이터 추출\n",
    "        row_i = row_i[row_i['card_id'] == card_i] # 정상거래 중 card_id가 i번째(-거래) card_id와 같은 데이터 추출\n",
    "        row_i = row_i[row_i['amount'] >= abs(amt_i)] # -거래와 절대값이 같거나 큰 결제정보 중\n",
    "        row_i = row_i[row_i['date'] <= date_i] # -거래 이전데이터 중 \n",
    "        if len(row_i[row_i['amount'] == abs(amt_i)]) > 0: # -거래 이전 거래중 절대값이 같은 거래가 있다면,,\n",
    "            row_i = row_i[row_i['amount'] == abs(amt_i)] # 여기 왜 필요?..\n",
    "            matched_row = row_i[row_i['date'] == max(row_i['date'])] # 가장 최근 시점 \n",
    "            # df_pos.loc[matched_row.index, 'amount'] = 0\n",
    "            df_pos = df_pos.loc[~df_pos.index.isin(matched_row.index), :] # matched_row에 해당하는 거래정보 제거(index이용)\n",
    "        elif len(row_i[row_i['amount'] > abs(amt_i)]) > 0: # -거래 이전 거래중 절대값이 더 큰 거래가 있다면,,\n",
    "            matched_row = row_i[row_i.date == max(row_i.date)]\n",
    "            df_pos.loc[matched_row.index, 'amount'] = matched_row.amount + amt_i # 차액만큼만\n",
    "        # else:\n",
    "        #     pass\n",
    "            # no_match.append(nega_i)\n",
    "#     end = datetime.now()\n",
    "#     time_took = (end - start).seconds / 60\n",
    "\n",
    "#     print(round(time_took, 2))\n",
    "    return df_pos # df_pos는 -거래 없는 데이터(-거래에 따른 환불처리까지)\n",
    "\n",
    "df_pos = reduce_noise_by_removing_neg_vals(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(y): # stationary test function\n",
    "    # perform Augmented Dickey Fuller test\n",
    "    print('Results of Augmented Dickey-Fuller test:')\n",
    "    dftest = adfuller(y, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['test statistic', 'p-value', '# of lags', '# of observations'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value ({})'.format(key)] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_diagnostics(y, lags=None, title='', filename=''):\n",
    "    '''\n",
    "    Calculate acf, pacf, qq plot and Augmented Dickey Fuller test for a given time series\n",
    "    '''\n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y)\n",
    "\n",
    "    # weekly moving averages (5 day window because of workdays)\n",
    "    rolling_mean = pd.Series.rolling(y, window=2).mean()\n",
    "    rolling_std = pd.Series.rolling(y, window=2).std()\n",
    "\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    layout = (3, 2)\n",
    "    ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n",
    "    acf_ax = plt.subplot2grid(layout, (1, 0))\n",
    "    pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "    qq_ax = plt.subplot2grid(layout, (2, 0))\n",
    "    hist_ax = plt.subplot2grid(layout, (2, 1))\n",
    "\n",
    "    # time series plot\n",
    "    y.plot(ax=ts_ax)\n",
    "    rolling_mean.plot(ax=ts_ax, color='crimson')\n",
    "    rolling_std.plot(ax=ts_ax, color='darkslateblue')\n",
    "    plt.legend(loc='best')\n",
    "    ts_ax.set_title(title, fontsize=24)\n",
    "\n",
    "    # acf and pacf\n",
    "    plot_acf(y, lags=lags, ax=acf_ax, alpha=0.5)\n",
    "    plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.5)\n",
    "\n",
    "    # qq plot\n",
    "    sm.qqplot(y, line='s', ax=qq_ax)\n",
    "    qq_ax.set_title('QQ Plot')\n",
    "\n",
    "    # hist plot\n",
    "    y.plot(ax=hist_ax, kind='hist', bins=25)\n",
    "    hist_ax.set_title('Histogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # perform Augmented Dickey Fuller test\n",
    "    print('Results of Dickey-Fuller test:')\n",
    "    dftest = adfuller(y, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['test statistic', 'p-value', '# of lags', '# of observations'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)' % key] = value\n",
    "    print(dfoutput)\n",
    "    return\n",
    "\n",
    "df = df_pos.copy()\n",
    "test_groupby_date_store = df.groupby(['date', 'store_id'])['amount', 'holyday'].sum()\n",
    "test_groupby_date_store = test_groupby_date_store.reset_index()\n",
    "\n",
    "test_groupby_date_store = test_groupby_date_store.set_index('date')\n",
    "store_list = test_groupby_date_store.store_id.unique()\n",
    "\n",
    "store_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
