{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 코드 (pymysql + crawling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymysql.connect(host='localhost', port=3306, user='root', passwd='3927', db='bestproducts', charset='utf8')\n",
    "cursor = db.cursor()\n",
    "\n",
    "res = requests.get('http://corners.gmarket.co.kr/Bestsellers')\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "categories = soup.select('div.gbest-cate ul.by-group li a')\n",
    "# for category in categories:\n",
    "#     get_category('http://corners.gmarket.co.kr/' + category['href'], category.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('http://corners.gmarket.co.kr/' + categories[0]['href'], categories[0].get_text())\n",
    "soup = BeautifulSoup(res.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = soup\n",
    "category_name = categories[0].get_text()\n",
    "subcategory_name = 'ALL'\n",
    "\n",
    "best_item = html.select('div.best-list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 페이지 구조\n",
    "## 전체ALL -> Main Category -> Main Category의 ALL -> subCategory\n",
    "\n",
    "#################################################################################################\n",
    "# main category list parsing\n",
    "def get_category(category_link, category_name): # 메인 카테고리링크, 메인카테고리명\n",
    "#     print(category_link, category_name)\n",
    "    res = requests.get(category_link) # 해당 메인카테고리 페이지로\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "    # get_items가 여기서 한번 아래에서 다시 한번(for문으로) 총 2번 실행된다\n",
    "    # 여기서는 각 main카테고리의 main 정보들을 parsing 한다.\n",
    "    get_items(soup, category_name, \"ALL\") # 여기서 ALL은 그냥 이름 지정위해 사용\n",
    "    \n",
    "    # 각 main 카테고리에서의 sub category 정보들을 파싱한다.\n",
    "    sub_categories = soup.select('div.navi.group ul li > a') # li 바로 밑에 a태그가 있는것만 추출\n",
    "    for sub_category in sub_categories:\n",
    "        res = requests.get('http://corners.gmarket.co.kr/' + sub_category['href'])\n",
    "        soup = BeautifulSoup(res.content, 'html.parser')\n",
    "        print(category_name, sub_category.get_text())\n",
    "        get_items(soup, category_name, sub_category.get_text()) # 각 sub_category 별로 정보 파싱\n",
    "        \n",
    "#################################################################################################\n",
    "\n",
    "# 정보 파싱하여 dict 형태로 저장\n",
    "def get_items(html, category_name, sub_category_name):\n",
    "    best_item = html.select('div.best-list')\n",
    "    # div.best-list tag가 여러개임 그 중 2번째가 필요\n",
    "    for index, item in enumerate(best_item[1].select('li')):\n",
    "        # 각각의 li별로 정보 수집하여 dict에 저장\n",
    "        data_dict = dict()\n",
    "\n",
    "        ranking = index + 1 \n",
    "        title = item.select_one('a.itemname')\n",
    "        ori_price = item.select_one('div.o-price')\n",
    "        dis_price = item.select_one('div.s-price strong span') # storng sapn태그까지 들어가야 정확.\n",
    "        discount_percent = item.select_one('div.s-price em')\n",
    "        \n",
    "        # ori_price와 dis_pirce가 없는 경우가 존재함.\n",
    "        if ori_price == None or ori_price.get_text() == '': # 태그가 아예 없는 경우 or 태그는 있으나 정보가 비어있는 경우\n",
    "            ori_price = dis_price\n",
    "\n",
    "        if dis_price == None:\n",
    "            ori_price, dis_price = 0, 0\n",
    "        else:\n",
    "            ori_price = ori_price.get_text().replace(',', '').replace('원', '')\n",
    "            dis_price = dis_price.get_text().replace(',', '').replace('원', '')\n",
    "\n",
    "        if discount_percent == None or discount_percent.get_text() == '':\n",
    "            discount_percent = 0\n",
    "        else:\n",
    "            discount_percent = discount_percent.get_text().replace('%', '')\n",
    "        \n",
    "        product_link = item.select_one('div.thumb > a') # 각 상품별 페이지 링크\n",
    "        item_code = product_link.attrs['href'].split('=')[1] # 상품 id만 추출\n",
    "\n",
    "        res = requests.get(product_link.attrs['href']) # 상품별 페이지로 \n",
    "        soup = BeautifulSoup(res.content, 'html.parser')\n",
    "        provider = soup.select_one('div.item-topinfo_headline > p > a > strong') # 판매자 파싱\n",
    "        if provider == None:\n",
    "            provider = ''\n",
    "        else:\n",
    "            provider = provider.get_text()\n",
    "\n",
    "        data_dict['category_name'] = category_name\n",
    "        data_dict['sub_category_name'] = sub_category_name\n",
    "        data_dict['ranking'] = ranking\n",
    "        data_dict['title'] = title.get_text()\n",
    "        data_dict['ori_price'] = ori_price\n",
    "        data_dict['dis_price'] = dis_price\n",
    "        data_dict['discount_percent'] = discount_percent\n",
    "        data_dict['item_code'] = item_code\n",
    "        data_dict['provider'] = provider\n",
    "\n",
    "        save_data(data_dict) # db에 insert\n",
    "        \n",
    "#################################################################################################\n",
    "\n",
    "\n",
    "# Main에서도 순위권이고 sub에서도 순위권인 상품의 경우 item_code가 중복됨. 이 경우 고려 \n",
    "def save_data(item_info):\n",
    "#     print (item_info)\n",
    "    \n",
    "    # 이미 존재하는 item_code인지 확인\n",
    "    sql = \"\"\"SELECT COUNT(*) FROM items WHERE item_code = '\"\"\" + item_info['item_code'] + \"\"\"';\"\"\"\n",
    "    cursor.execute(sql)\n",
    "    result = cursor.fetchone()\n",
    "    \n",
    "    if result[0] == 0: # 새로들어오는 item_code라면 \n",
    "        sql = \"\"\"INSERT INTO items VALUES('\"\"\" + item_info['item_code'] + \"\"\"',\n",
    "        '\"\"\" + item_info['title'] + \"\"\"', \n",
    "        \"\"\" + str(item_info['ori_price']) + \"\"\", \n",
    "        \"\"\" + str(item_info['dis_price']) + \"\"\", \n",
    "        \"\"\" + str(item_info['discount_percent']) + \"\"\", \n",
    "        '\"\"\" + item_info['provider'] + \"\"\"')\"\"\"\n",
    "        print (sql)\n",
    "        cursor.execute(sql)\n",
    "    \n",
    "    # item_code가 이미 존재한다면 여기만 실행\n",
    "    sql = \"\"\"INSERT INTO ranking (main_category, sub_category, item_ranking, item_code) VALUES('\"\"\" + item_info['category_name'] + \"\"\"',\n",
    "    '\"\"\" + item_info['sub_category_name'] + \"\"\"', \n",
    "    '\"\"\" + str(item_info['ranking']) + \"\"\"', \n",
    "    '\"\"\" + item_info['item_code'] + \"\"\"')\"\"\"     \n",
    "    print (sql)    \n",
    "    cursor.execute(sql)\n",
    "    \n",
    "#################################################################################################\n",
    "\n",
    "db = pymysql.connect(host='localhost', port=3306, user='root', passwd='3927', db='bestproducts', charset='utf8')\n",
    "cursor = db.cursor()\n",
    "\n",
    "res = requests.get('http://corners.gmarket.co.kr/Bestsellers')\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "categories = soup.select('div.gbest-cate ul.by-group li a')\n",
    "for category in categories:\n",
    "    get_category('http://corners.gmarket.co.kr/' + category['href'], category.get_text())\n",
    "\n",
    "db.commit()\n",
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
