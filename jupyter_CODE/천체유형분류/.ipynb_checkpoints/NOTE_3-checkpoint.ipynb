{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.3f'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,KFold,cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier,VotingClassifier,BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "%precision 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/KIHyuk/Desktop/dacon_data/Data_천체유형분류/train.csv',index_col=0)\n",
    "test = pd.read_csv('C:/Users/KIHyuk/Desktop/dacon_data/Data_천체유형분류/test.csv',index_col=0)\n",
    "sample_submission = pd.read_csv('C:/Users/KIHyuk/Desktop/dacon_data/Data_천체유형분류/sample_submission.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data preprocessing\n",
    "\n",
    "column_number = {}\n",
    "for i, column in enumerate(sample_submission.columns):\n",
    "    column_number[column] = i\n",
    "    \n",
    "def to_number(x, dic):\n",
    "    return dic[x]\n",
    "\n",
    "train['type_num'] = train['type'].apply(lambda x: to_number(x, column_number))\n",
    "\n",
    "train = train.drop(['fiberID'],axis=1) # del fiberID column\n",
    "test = test.drop(['fiberID'],axis=1)\n",
    "\n",
    "# split train/test\n",
    "# strtify => 클래스 비율 유지\n",
    "train_x,test_x,train_y,test_y = train_test_split(train.drop(columns=['type', 'type_num'], axis=1),train['type_num'],random_state=2,stratify=train['type_num'])\n",
    "\n",
    "# for submission\n",
    "res_train_x = train.drop(columns=['type', 'type_num'], axis=1)\n",
    "res_train_y = train['type_num']\n",
    "res_test_x = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained variance ratio : [0.383 0.14  0.079 0.069 0.058 0.049 0.045 0.043 0.033 0.029 0.026]\n",
      "선택한 차원(픽셀) 수 : 11\n"
     ]
    }
   ],
   "source": [
    "# pca = PCA(n_components=0.95,random_state=2)\n",
    "# pca_train_x = pca.fit_transform(sc_train_x)\n",
    "# pca_test_x = pca.transform(sc_test_x) # * transform \n",
    "\n",
    "# print('explained variance ratio :', pca.explained_variance_ratio_) # 주성분별 분산 설명 비율 (*설명비율)\n",
    "# print('선택한 차원(픽셀) 수 :', pca.n_components_) # 95%의 분산 설명을 위해 몇개의 차원을 선택했는가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_x,train_y,test_x,test_y]\n",
    "model_info = ['logistic',LogisticRegression()]\n",
    "\n",
    "grid_params_lr = [{'logistic__penalty': ['l1', 'l2'],\n",
    "                   'logistic__C': [0.001,0.01,10,100],\n",
    "                   'logistic__solver': ['liblinear'],\n",
    "                   'logistic__random_state':[2]\n",
    "                  }] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling(data,model_info,grid_params_lr,target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = list(train['type'].unique())\n",
    "def modeling(data, model_info, params, target_name): # target_name 고정시키기\n",
    "    \n",
    "    train_x,train_y = data[0],data[1]\n",
    "    test_x,test_y = data[2],data[3]\n",
    "    \n",
    "    scaler = ('scaler',StandardScaler())\n",
    "    model = (model_info[0],model_info[1])\n",
    "    pipe = Pipeline([scaler,model])\n",
    "    \n",
    "    grid = GridSearchCV(pipe, param_grid=params, cv=5,n_jobs=-1,refit=True) # refit => True\n",
    "    grid.fit(train_x,train_y)\n",
    "    \n",
    "    best_param = grid.best_params_\n",
    "    print(\"####################################################\")\n",
    "    print(\"best params:{}\".format(grid.best_params_))\n",
    "    print(\"####################################################\")\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    predict = grid.predict() # refit=True => best params로 예측 \n",
    "    print(classification_report(test_y,prediction,target_names=target_name))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    predict_proba = grid.predict_proba()\n",
    "    print(\"logloss : \",log_loss(test_y,predict_proba))\n",
    "    \n",
    "    result_list = [best_param,predict,predict_proba]\n",
    "    \n",
    "    return result_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
