{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.3f'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "%precision 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2^6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/KIHyuk/Desktop/dacon_data/Data_천체유형분류/train.csv',index_col=0)\n",
    "test = pd.read_csv('C:/Users/KIHyuk/Desktop/dacon_data/Data_천체유형분류/test.csv',index_col=0)\n",
    "sample_submission = pd.read_csv('C:/Users/KIHyuk/Desktop/dacon_data/Data_천체유형분류/sample_submission.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train.type = label_encoder.fit_transform(train.type)\n",
    "\n",
    "res_train_y = train.type\n",
    "res_train_x = train.iloc[:,1:]\n",
    "\n",
    "res_test_x = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(train.iloc[:,1:],train.type,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ Random Forest\n",
    "############################################################################\n",
    "estimators = 100\n",
    "np.random.seed(2)\n",
    "RF_model = RandomForestClassifier(n_estimators = estimators)\n",
    "RF_model.fit(train_x, train_y)\n",
    "RF_prediction = RF_model.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss :  0.4781892666217565\n"
     ]
    }
   ],
   "source": [
    "# 100\n",
    "print(\"log_loss : \",log_loss(test_y,RF_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_RF = pd.DataFrame(data=RF_prediction, columns=sample_submission.columns, index=test_x.index)\n",
    "submission_RF.to_csv('submission_RF.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ Ada Boosting\n",
    "############################################################################\n",
    "estimator = DecisionTreeClassifier(max_depth=3,random_state=2,criterion='entropy')\n",
    "ADA_model = AdaBoostClassifier(base_estimator=estimator,\n",
    "                               n_estimators=500,\n",
    "                               random_state=2,\n",
    "                               learning_rate=0.1\n",
    "                              )\n",
    "\n",
    "ADA_model.fit(train_x,train_y)\n",
    "ADA_prediction = ADA_model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"log_loss : \",log_loss(test_y,ADA_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ GBM\n",
    "############################################################################\n",
    "estimators = 50\n",
    "np.random.seed(2)\n",
    "GBM_model = GradientBoostingClassifier(n_estimators = estimators)\n",
    "GBM_model.fit(train_x, train_y)\n",
    "GBM_prediction = GBM_model.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"log loss : \",log_loss(test_y,GBM_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_GBM = pd.DataFrame(data=GBM_prediction, columns=sample_submission.columns, index=test_x.index)\n",
    "submission_GBM.to_csv('submission_GBM.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "############################################################################\n",
    "############ XGBOOST\n",
    "############################################################################\n",
    "dtrain_prod = xgb.DMatrix(data = train_x, label = train_y)\n",
    "dtest_prod = xgb.DMatrix(data = test_x,label=test_y)\n",
    "\n",
    "# Custom error function for the XGB model\n",
    "threshold = 0.5\n",
    "def eval_error(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = (preds > threshold ).astype('float')\n",
    "    return \"accuracy\", accuracy_score(labels, preds)\n",
    "\n",
    "param = {'objective' : 'multi:softprob',\n",
    "         'max_depth' : 9,\n",
    "         'eta': 0.3,\n",
    "         'num_class': 19\n",
    "#          'colsample_bytree' : 1,\n",
    "#          'subsample' : 1\n",
    "         }\n",
    "\n",
    "\n",
    "nrounds = 2\n",
    "\n",
    "np.random.seed(2)\n",
    "XGB_model = xgb.train(param, \n",
    "                      dtrain_prod, \n",
    "                      num_boost_round = nrounds ,\n",
    "                      feval = eval_error,\n",
    "                      maximize = True,\n",
    "#                       early_stopping_rounds = 10,\n",
    "                      )\n",
    "\n",
    "XGB_prediction = XGB_model.predict(dtest_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss :  0.953463232917742\n"
     ]
    }
   ],
   "source": [
    "print(\"log loss : \",log_loss(test_y,XGB_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_XGB = pd.DataFrame(data=XGB_prediction, columns=sample_submission.columns, index=test_x.index)\n",
    "submission_XGB.to_csv('submission_XGB.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "#Ensembling the three models\n",
    "############################################################################\n",
    "\n",
    "#Forming the ensemble dataset of the 3 models\n",
    "# ensemble = pd.DataFrame()\n",
    "# ensemble = (submission_XGB + submission_GBM + submission_RF)/3\n",
    "\n",
    "# #Printing to see all the hospitals that are classified as closed \n",
    "# print(ensemble.loc[ensemble['OC'] == 0, ])\n",
    "\n",
    "# ensemble = ensemble.loc[:, ['inst_id', 'OC']]\n",
    "\n",
    "# ensemble.to_csv('ens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "parameters = {\n",
    "     \"eta\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    "     \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "     \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "     \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "     \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "     }\n",
    "\n",
    "grid = GridSearchCV(clf,\n",
    "                    parameters, n_jobs=4,\n",
    "                    scoring=\"neg_log_loss\",\n",
    "                    cv=3)\n",
    "\n",
    "grid.fit(train_x, train_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
