{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.datasets import CachedDatasets\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance, \\\n",
    "    TimeSeriesResampler\n",
    "from tslearn.utils import to_time_series\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "from tslearn.clustering import TimeSeriesKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager, rc\n",
    "import matplotlib\n",
    "\n",
    "#한글 폰트 등록\n",
    "font_location = \"c:/Windows/fonts/malgun.ttf\"\n",
    "font_name = font_manager.FontProperties(fname=font_location).get_name()\n",
    "matplotlib.rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 판다스 데이터프레임(DataFrame)을 출력할 때, 최대 출력할 수 있는 컬럼을 100개로 늘려줍니다.\n",
    "# # 이렇게 해야 데이터를 분석할 때 출력해서 확인하기 편합니다.\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/KIHyuk/Desktop/전력수요예측/train.csv')\n",
    "test = pd.read_csv('C:/Users/KIHyuk/Desktop/전력수요예측/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### train 결측치 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 번째 실행중\n",
      "100 번째 실행중\n",
      "150 번째 실행중\n",
      "200 번째 실행중\n",
      "250 번째 실행중\n",
      "300 번째 실행중\n",
      "350 번째 실행중\n",
      "400 번째 실행중\n",
      "450 번째 실행중\n",
      "500 번째 실행중\n",
      "550 번째 실행중\n",
      "600 번째 실행중\n",
      "650 번째 실행중\n",
      "700 번째 실행중\n",
      "750 번째 실행중\n",
      "800 번째 실행중\n",
      "850 번째 실행중\n",
      "900 번째 실행중\n",
      "950 번째 실행중\n",
      "1000 번째 실행중\n",
      "1050 번째 실행중\n",
      "1100 번째 실행중\n",
      "1150 번째 실행중\n",
      "1200 번째 실행중\n",
      "1250 번째 실행중\n",
      "1300 번째 실행중\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,len(train.columns) ): #시간을 제외한 1열부터 마지막 열까지를 for문으로 작동시킵니다.\n",
    "    train_median=train.iloc[:,k].median() #값을 대체하는 과정에서 값이 변경 될 것을 대비해 해당 세대의 중앙값을 미리 계산하고 시작합니다.\n",
    "    counting=train.loc[ train.iloc[:,k].isnull()==False ][ train.columns[k] ].index\n",
    "\n",
    "    df=pd.DataFrame( list( zip( counting[:-1], counting[1:] - counting[:-1] -1  ) ), columns=['index','count'] )\n",
    "    \n",
    "    df2= df[ (df['count'] > 0) ] #결측치가 존재하는 부분만 추출\n",
    "    df2=df2.reset_index(drop=True) #기존에 존재하는 index를 초기화 하여 이후 for문에 사용함\n",
    "\n",
    "    for i,j in zip( df2['index'], df2['count'] ) : # i = 해당 세대에서 값이 존재하는 index, j = 현재 index 밑의 결측치 갯수\n",
    "        if train.iloc[i,k]>=train_median: #현재 index에 존재하는 값이 해당 세대의 중앙 값 이상일때만 분산처리 실행\n",
    "            train.iloc[ i : i+j+1 , k] = train.iloc[i,k] / (j+1) \n",
    "            #현재 index 및 결측치의 갯수 만큼 지정을 하여, 현재 index에 있는 값을 해당 갯수만큼 나누어 줍니다\n",
    "        else:\n",
    "            pass\n",
    "            #현재 index에 존재하는 값이 중앙 값 미만이면 pass를 실행\n",
    "    if k%50==0: #for문 진행정도 확인용\n",
    "            print(k,\"번째 실행중\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 번째 실행중\n",
      "100 번째 실행중\n",
      "150 번째 실행중\n",
      "200 번째 실행중\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,len(test.columns) ): #시간을 제외한 1열부터 마지막 열까지를 for문으로 작동시킵니다.\n",
    "    test_median=test.iloc[:,k].median() #값을 대체하는 과정에서 값이 변경 될 것을 대비해 해당 세대의 중앙값을 미리 계산하고 시작합니다.\n",
    "    counting=test.loc[ test.iloc[:,k].isnull()==False ][ test.columns[k] ].index\n",
    "\n",
    "    df=pd.DataFrame( list( zip( counting[:-1], counting[1:] - counting[:-1] -1  ) ), columns=['index','count'] )\n",
    "    \n",
    "    df2= df[ (df['count'] > 0) ] #결측치가 존재하는 부분만 추출\n",
    "    df2=df2.reset_index(drop=True) #기존에 존재하는 index를 초기화 하여 이후 for문에 사용함\n",
    "\n",
    "    for i,j in zip( df2['index'], df2['count'] ) : # i = 해당 세대에서 값이 존재하는 index, j = 현재 index 밑의 결측치 갯수\n",
    "        if test.iloc[i,k]>=test_median: #현재 indetestx에 존재하는 값이 해당 세대의 중앙 값 이상일때만 분산처리 실행\n",
    "            test.iloc[ i : i+j+1 , k] = test.iloc[i,k] / (j+1) \n",
    "            #현재 index 및 결측치의 갯수 만큼 지정을 하여, 현재 index에 있는 값을 해당 갯수만큼 나누어 줍니다\n",
    "        else:\n",
    "            pass\n",
    "            #현재 index에 존재하는 값이 중앙 값 미만이면 pass를 실행\n",
    "    if k%50==0: #for문 진행정도 확인용\n",
    "            print(k,\"번째 실행중\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Time'] = train['Time'].apply(pd.to_datetime)\n",
    "train.set_index('Time',inplace=True)\n",
    "\n",
    "test['Time'] = test['Time'].apply(pd.to_datetime)\n",
    "test.set_index('Time',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train['2018-02-15':]\n",
    "train_sample = train_sample.interpolate(method='time')\n",
    "\n",
    "test_sample = test['2018-02-15':]\n",
    "test_sample = test_sample.interpolate(method='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X4', 'X127', 'X9', 'X65', 'X54', 'X13', 'X53', 'X24', 'X17', 'X14',\n",
       "       'X48', 'X2', 'X19', 'X36', 'X28', 'X63', 'X38', 'X39', 'X8', 'X64',\n",
       "       'X29', 'X57', 'X705', 'X71', 'X3', 'X27', 'X22', 'X21', 'X118', 'X6',\n",
       "       'X45', 'X40', 'X66', 'X52', 'X12', 'X49', 'X1', 'X33', 'X60', 'X46',\n",
       "       'X963', 'X56', 'X15', 'X11', 'X25', 'X34', 'X23', 'X58'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#결측값 가진 행 제거 - 데이터가 아예 없는 경우\n",
    "train_sample.loc[:,train_sample.isnull().sum() >= 1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X26', 'X16', 'X7', 'X18', 'X41', 'X55', 'X5', 'X43', 'X59', 'X10',\n",
       "       'X62', 'X61', 'X32', 'X31', 'X30', 'X51', 'X35', 'X44', 'X37', 'X42',\n",
       "       'X50', 'X47', 'X20'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#결측값 가진 행 제거 - 데이터가 아예 없는 경우\n",
    "test_sample.loc[:,test_sample.isnull().sum() >= 1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample.drop(['X4', 'X127', 'X9', 'X65', 'X54', 'X13', 'X53', 'X24', 'X17', 'X14',\n",
    "       'X48', 'X2', 'X19', 'X36', 'X28', 'X63', 'X38', 'X39', 'X8', 'X64',\n",
    "       'X29', 'X57', 'X705', 'X71', 'X3', 'X27', 'X22', 'X21', 'X118', 'X6',\n",
    "       'X45', 'X40', 'X66', 'X52', 'X12', 'X49', 'X1', 'X33', 'X60', 'X46',\n",
    "       'X963', 'X56', 'X15', 'X11', 'X25', 'X34', 'X23', 'X58'], axis=1, inplace=True)\n",
    "\n",
    "test_sample.drop(['X26', 'X16', 'X7', 'X18', 'X41', 'X55', 'X5', 'X43', 'X59', 'X10',\n",
    "       'X62', 'X61', 'X32', 'X31', 'X30', 'X51', 'X35', 'X44', 'X37', 'X42',\n",
    "       'X50', 'X47', 'X20'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 1252)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.resample(rule='D').sum().values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted = to_time_series_dataset(train_sample.resample(rule='D').sum().values.reshape(136,1252,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12727.472 --> 8493.893 --> 8253.633 --> 8052.337 --> 7993.410 --> 7990.561 --> 7990.561 --> \n"
     ]
    }
   ],
   "source": [
    "km = TimeSeriesKMeans(n_clusters=5, verbose=True, random_state=0)\n",
    "y_pred = km.fit_predict(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Romain Tavenard\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.datasets import CachedDatasets\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance, \\\n",
    "    TimeSeriesResampler\n",
    "\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "X_train, y_train, X_test, y_test = CachedDatasets().load_dataset(\"Trace\")\n",
    "X_train = X_train[y_train < 4]  # Keep first 3 classes\n",
    "numpy.random.shuffle(X_train)\n",
    "# Keep only 50 time series\n",
    "X_train = TimeSeriesScalerMeanVariance().fit_transform(X_train[:50])\n",
    "# Make time series shorter\n",
    "X_train = TimeSeriesResampler(sz=40).fit_transform(X_train)\n",
    "sz = X_train.shape[1]\n",
    "\n",
    "# Euclidean k-means\n",
    "print(\"Euclidean k-means\")\n",
    "km = TimeSeriesKMeans(n_clusters=3, verbose=True, random_state=seed)\n",
    "y_pred = km.fit_predict(X_train)\n",
    "\n",
    "plt.figure()\n",
    "for yi in range(3):\n",
    "    plt.subplot(3, 3, yi + 1)\n",
    "    for xx in X_train[y_pred == yi]:\n",
    "        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "    plt.xlim(0, sz)\n",
    "    plt.ylim(-4, 4)\n",
    "    if yi == 1:\n",
    "        plt.title(\"Euclidean $k$-means\")\n",
    "\n",
    "# DBA-k-means\n",
    "# print(\"DBA k-means\")\n",
    "# dba_km = TimeSeriesKMeans(n_clusters=3,\n",
    "#                           n_init=2,\n",
    "#                           metric=\"dtw\",\n",
    "#                           verbose=True,\n",
    "#                           max_iter_barycenter=10,\n",
    "#                           random_state=seed)\n",
    "# y_pred = dba_km.fit_predict(X_train)\n",
    "\n",
    "# for yi in range(3):\n",
    "#     plt.subplot(3, 3, 4 + yi)\n",
    "#     for xx in X_train[y_pred == yi]:\n",
    "#         plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "#     plt.plot(dba_km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "#     plt.xlim(0, sz)\n",
    "#     plt.ylim(-4, 4)\n",
    "#     if yi == 1:\n",
    "#         plt.title(\"DBA $k$-means\")\n",
    "\n",
    "# # Soft-DTW-k-means\n",
    "# print(\"Soft-DTW k-means\")\n",
    "# sdtw_km = TimeSeriesKMeans(n_clusters=3,\n",
    "#                            metric=\"softdtw\",\n",
    "#                            metric_params={\"gamma_sdtw\": .01},\n",
    "#                            verbose=True,\n",
    "#                            random_state=seed)\n",
    "# y_pred = sdtw_km.fit_predict(X_train)\n",
    "\n",
    "# for yi in range(3):\n",
    "#     plt.subplot(3, 3, 7 + yi)\n",
    "#     for xx in X_train[y_pred == yi]:\n",
    "#         plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "#     plt.plot(sdtw_km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "#     plt.xlim(0, sz)\n",
    "#     plt.ylim(-4, 4)\n",
    "#     if yi == 1:\n",
    "#         plt.title(\"Soft-DTW $k$-means\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
