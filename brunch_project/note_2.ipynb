{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'C:/Users/KIHyuk/Desktop/brunch_data/json'\n",
    "\n",
    "def get_file_list(dir_name): # file name들을 가져오는 함수 # 폴더명 인자 # 폴더가 위치한 경로를 인자로\n",
    "    return os.listdir(dir_name) # 폴더 내 파일명을 리스트 형태로 반환 \n",
    "\n",
    "file_list = get_file_list(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_keyword(x):\n",
    "    tmp = []\n",
    "    for val in x:\n",
    "        tmp.append(val.replace(\"\\n\",\"\").replace(\" \",\"\"))\n",
    "    return tmp\n",
    "\n",
    "def pre_comment(x):\n",
    "    if len(x) == 0:\n",
    "        return None\n",
    "    else :\n",
    "        return x\n",
    "\n",
    "def pre_text(x):\n",
    "    return str(x)\n",
    "\n",
    "class_condition = {'지구한바퀴_세계여행':0 , '그림·웹툰':1, '시사·이슈':2, 'IT_트렌드':3, '사진·촬영':4, '취향저격_영화_리뷰':5,\n",
    "                   '뮤직_인사이드':6, '육아_이야기':7, '요리·레시피':8, '건강·운동':9, '멘탈_관리_심리_탐구':10, '문화·예술':11, '건축·설계':12,\n",
    "                   '인문학·철학':13, '쉽게_읽는_역사':14, '우리집_반려동물':15, '글쓰기_코치':16, '오늘은_이런_책':16, '직장인_현실_조언':17, '스타트업_경험담':17,\n",
    "                   '디자인_스토리':18, '멋진_캘리그래피':18, '사랑·이별':19, '감성_에세이':19}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_df = pd.DataFrame(columns=['class','text'])\n",
    "each_df = {}\n",
    "\n",
    "for file in file_list:\n",
    "    with open('C:/Users/KIHyuk/Desktop/brunch_data/json/'+file,encoding='UTF8') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    \n",
    "    df = pd.DataFrame(json_data['data'],\n",
    "                  columns=['title','keyword','text','nickname','publish_date','likes','share','comment','url','url_plink'])\n",
    "    df = df.dropna(subset=['text'])\n",
    "    df['keyword'] = df['keyword'].apply(pre_keyword)\n",
    "    df['comment'] = df['comment'].apply(pre_comment)\n",
    "    df['text'] = df['text'].apply(pre_text)\n",
    "    df.insert(0,\"class\",file[:-5])\n",
    "#     df['class'] = df['class'].map(class_condition)\n",
    "    \n",
    "    all_df = pd.concat([all_df,df[['class','text','keyword','publish_date','likes','share','comment','url']][:100]])\n",
    "    each_df[file[:-5]] = df\n",
    "    \n",
    "all_df = all_df.reset_index(drop=True)\n",
    "\n",
    "def split_datetime(x):\n",
    "    return x.split('T')[0]\n",
    "\n",
    "all_df['publish_date'] = all_df['publish_date'].apply(split_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>keyword</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>IT_트렌드</td>\n",
       "      <td>[서핑, 넷플릭스, 모바일]</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>['요즘 집콕하는 시간이 길어지다 보니 넷플릭스에 접속하는 시간이 길어졌다. 그렇다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>IT_트렌드</td>\n",
       "      <td>[코로나, 재택근무, 애플]</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>['', \"타겟 유저, 타겟 시장이라는 용어를 흔히들 씁니다. 신사업을 기획하거나 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>IT_트렌드</td>\n",
       "      <td>[디자인, UX, UI]</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>['', '-지난글 보기-', 'https://brunch.co.kr/@sei0/8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>IT_트렌드</td>\n",
       "      <td>[애플, 안경, 아이패드프로]</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>['텐서플로우 개발자 서밋에\\xa0이어 두 번째로 인공지능 기조연설\\xa0시리즈를 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>IT_트렌드</td>\n",
       "      <td>[지니, UI디자인, UX]</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>['작업 초반에는 태블릿에 앱을 탑재해 적용된 화면을 보며 진행하였기에 큰 문제없이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2395</td>\n",
       "      <td>취향저격_영화_리뷰</td>\n",
       "      <td>[예술, 영화, 존재]</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>[\"예술경영인의 눈으로 바라보는 '존재'의 의미 예술영화&lt;벌새&gt;를 통하여\", '',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2396</td>\n",
       "      <td>취향저격_영화_리뷰</td>\n",
       "      <td>[영화, 인정, 주인공]</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>['', '뉴스를 틀면 늘 한숨부터 나옵니다. 세상엔 어쩜 이렇게 나쁜 사람도, 속...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2397</td>\n",
       "      <td>취향저격_영화_리뷰</td>\n",
       "      <td>[영화, 영화리뷰, 공감에세이]</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>['', '\\xa0잘 만든 영화라는 느낌을 받을 때가 있다. 색감이 완벽하거나, 배...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2398</td>\n",
       "      <td>취향저격_영화_리뷰</td>\n",
       "      <td>[모리, 영화, 리뷰]</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>['두 지팡이를 힘겹게 짚고 걷던 구마가이 모리카즈(야마자키 츠토무)는 길가에 난 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2399</td>\n",
       "      <td>취향저격_영화_리뷰</td>\n",
       "      <td>[투명인간, 영화리뷰, 공포영화]</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>[\"1. 멋진 저택에서 남편인 '애드리안(올리버 잭슨 코헨)'과 함께 사는 '세실리...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           class             keyword publish_date  \\\n",
       "0         IT_트렌드     [서핑, 넷플릭스, 모바일]   2020-03-30   \n",
       "1         IT_트렌드     [코로나, 재택근무, 애플]   2020-03-30   \n",
       "2         IT_트렌드       [디자인, UX, UI]   2020-03-30   \n",
       "3         IT_트렌드    [애플, 안경, 아이패드프로]   2020-03-30   \n",
       "4         IT_트렌드     [지니, UI디자인, UX]   2020-03-30   \n",
       "...          ...                 ...          ...   \n",
       "2395  취향저격_영화_리뷰        [예술, 영화, 존재]   2020-03-27   \n",
       "2396  취향저격_영화_리뷰       [영화, 인정, 주인공]   2020-03-27   \n",
       "2397  취향저격_영화_리뷰   [영화, 영화리뷰, 공감에세이]   2020-03-27   \n",
       "2398  취향저격_영화_리뷰        [모리, 영화, 리뷰]   2020-03-27   \n",
       "2399  취향저격_영화_리뷰  [투명인간, 영화리뷰, 공포영화]   2020-03-27   \n",
       "\n",
       "                                                   text  \n",
       "0     ['요즘 집콕하는 시간이 길어지다 보니 넷플릭스에 접속하는 시간이 길어졌다. 그렇다...  \n",
       "1     ['', \"타겟 유저, 타겟 시장이라는 용어를 흔히들 씁니다. 신사업을 기획하거나 ...  \n",
       "2     ['', '-지난글 보기-', 'https://brunch.co.kr/@sei0/8...  \n",
       "3     ['텐서플로우 개발자 서밋에\\xa0이어 두 번째로 인공지능 기조연설\\xa0시리즈를 ...  \n",
       "4     ['작업 초반에는 태블릿에 앱을 탑재해 적용된 화면을 보며 진행하였기에 큰 문제없이...  \n",
       "...                                                 ...  \n",
       "2395  [\"예술경영인의 눈으로 바라보는 '존재'의 의미 예술영화<벌새>를 통하여\", '',...  \n",
       "2396  ['', '뉴스를 틀면 늘 한숨부터 나옵니다. 세상엔 어쩜 이렇게 나쁜 사람도, 속...  \n",
       "2397  ['', '\\xa0잘 만든 영화라는 느낌을 받을 때가 있다. 색감이 완벽하거나, 배...  \n",
       "2398  ['두 지팡이를 힘겹게 짚고 걷던 구마가이 모리카즈(야마자키 츠토무)는 길가에 난 ...  \n",
       "2399  [\"1. 멋진 저택에서 남편인 '애드리안(올리버 잭슨 코헨)'과 함께 사는 '세실리...  \n",
       "\n",
       "[2400 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_trend_chart(df,select_keyword,resampling_num):    \n",
    "    if resampling_num == 'M':\n",
    "        df = df['keyword']['2020-01-01':].resample('M').sum()\n",
    "    else:\n",
    "        df = df['keyword']['2020-01-01':].resample(resampling_num + 'D').sum()\n",
    "    \n",
    "    res_df = pd.DataFrame(columns=select_keyword,index=df.index)\n",
    "    for keyword in select_keyword:\n",
    "        keyword_week_count = []\n",
    "        for week in range(len(df)):\n",
    "            keyword_week_count.append(df.iloc[week].count(keyword))\n",
    "        res_df[keyword] = keyword_week_count\n",
    "        \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>감성에세이</th>\n",
       "      <th>여행</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publish_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>52</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>116</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              감성에세이  여행\n",
       "publish_date           \n",
       "2020-01-01        1   0\n",
       "2020-01-15        2   0\n",
       "2020-01-29        3   0\n",
       "2020-02-12        8  22\n",
       "2020-02-26       39  39\n",
       "2020-03-11       52  69\n",
       "2020-03-25      116  44\n",
       "2020-04-08        0   0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_trend_chart(all_df_copy,[\"감성에세이\",\"여행\"],'14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(all_df['text'],all_df['class'],test_size=0.2 ,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "def okt_tokenizer(text):\n",
    "    tokens_ko = okt.morphs(text)\n",
    "    return tokens_ko\n",
    "\n",
    "import re\n",
    "\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "train_data = []\n",
    "for sentence in X_train[:5]:\n",
    "#     temp_X = []\n",
    "    sentence = re.sub(r'[^0-9a-zA-Zㄱ-힗]',' ',sentence)\n",
    "    sentence = re.sub(r'[xa0]','',sentence)\n",
    "#     temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "#     temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    train_data.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(tokenizer=tw_tokenizer, ngram_range=(1,2), min_df=3, max_df=0.9)\n",
    "tfidf_vect.fit(X_train)\n",
    "tfidf_matrix_train = tfidf_vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_clf = LogisticRegression(random_state=0)\n",
    "\n",
    "params = {'C' :[1, 3.5, 4.5, 5.5, 10]}\n",
    "\n",
    "grid_cv = GridSearchCV(lg_clf, parma_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_cv.fit(tfidf_matrix_train,y_train)\n",
    "print(grid_cv.best_params_, round(grid_cv.best_score_,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
