{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "dir_name = 'C:/Users/KIHyuk/Desktop/brunch_data/json'\n",
    "\n",
    "def get_file_list(dir_name): # file name들을 가져오는 함수 # 폴더명 인자 # 폴더가 위치한 경로를 인자로\n",
    "    return os.listdir(dir_name) # 폴더 내 파일명을 리스트 형태로 반환 \n",
    "\n",
    "file_list = get_file_list(dir_name)\n",
    "\n",
    "## \\n, 공백 제거 후 리스트 형식으로 변환\n",
    "def pre_keyword(x):\n",
    "    tmp = []\n",
    "    for val in x:\n",
    "        tmp.append(val.replace(\"\\n\",\"\").replace(\" \",\"\"))\n",
    "    return tmp\n",
    "\n",
    "# comment가 없는경우 공백이 아닌 Nan으로 변환\n",
    "def pre_comment(x):\n",
    "    if len(x) == 0:\n",
    "        return None\n",
    "    else :\n",
    "        return x\n",
    "# 문자열로 변환\n",
    "def pre_text(x):\n",
    "    return str(x)\n",
    "\n",
    "# datetime 형식으로 변환\n",
    "def pre_datetime(x):\n",
    "    x = x.split('T')[0]\n",
    "    x = pd.to_datetime(x,format=\"%Y-%m-%d\")\n",
    "    return x\n",
    "\n",
    "# 각 카테고리를 0~19의 라벨로 변환 \n",
    "class_condition = {'지구한바퀴_세계여행':0 , '그림·웹툰':1, '시사·이슈':2, 'IT_트렌드':3, '사진·촬영':4, '취향저격_영화_리뷰':5,\n",
    "                   '뮤직_인사이드':6, '육아_이야기':7, '요리·레시피':8, '건강·운동':9, '멘탈_관리_심리_탐구':10, '문화·예술':11, '건축·설계':12,\n",
    "                   '인문학·철학':13, '쉽게_읽는_역사':14, '우리집_반려동물':15, '글쓰기_코치':16, '오늘은_이런_책':16, '직장인_현실_조언':17, '스타트업_경험담':17,\n",
    "                   '디자인_스토리':18, '멋진_캘리그래피':18, '사랑·이별':19, '감성_에세이':19}\n",
    "\n",
    "all_df = pd.DataFrame(columns=['class','text'])\n",
    "each_df = {}\n",
    "\n",
    "for file in file_list:\n",
    "    with open('C:/Users/KIHyuk/Desktop/brunch_data/json/'+file,encoding='UTF8') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    \n",
    "    df = pd.DataFrame(json_data['data'],\n",
    "                  columns=['title','keyword','text','nickname','publish_date','likes','share','comment','url','url_plink'])\n",
    "    df = df.dropna(subset=['text'])\n",
    "    df['keyword'] = df['keyword'].apply(pre_keyword)\n",
    "    df['comment'] = df['comment'].apply(pre_comment)\n",
    "    df['text'] = df['text'].apply(pre_text)\n",
    "    df['publish_date'] = df['publish_date'].apply(pre_datetime)\n",
    "    df.insert(0,\"class\",file[:-5])\n",
    "\n",
    "    all_df = pd.concat([all_df,df[['class','title','text','keyword','likes','share','comment','publish_date','url']]])\n",
    "    each_df[file[:-5]] = df\n",
    "\n",
    "all_df['class'] = all_df['class'].map(class_condition)\n",
    "all_df['class'] = all_df['class'].astype('category')\n",
    "all_df = all_df.dropna(subset=['class'])\n",
    "all_df = all_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def pre_text_2(x):\n",
    "    pa = re.compile(\"^\\\\\\\\xa0|xa\")\n",
    "    pa1 = re.compile(r\"'http.*?'\") # 전체 url 제거\n",
    "    pa2 = re.compile(r'\\([^)]*\\)') # () 사이 문자  \n",
    "    pa3 = re.compile('[^\\w\\s]') # 특수문자 삭제\n",
    "    pa4 = re.compile(r'[^a-zA-Zㄱ-힗]')\n",
    "\n",
    "    x = re.sub(pa,' ',x)\n",
    "    x = re.sub(pa1,' ',x)\n",
    "    x = re.sub(pa2,' ',x)\n",
    "    x = re.sub(pa3, ' ',x)\n",
    "    x = re.sub(pa4, ' ',x)\n",
    "    x = x.strip()\n",
    "    x = \" \".join(x.split())\n",
    "    return x \n",
    "\n",
    "all_df['text'] = all_df['text'].apply(pre_text_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
