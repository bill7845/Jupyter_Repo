{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. pandas로 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   # pandas 패키지 불러오기\n",
    "import numpy as np    # numpy 패키지 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "> pandas로 csv파일 불러오기 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'bank_customer.csv' does not exist: b'bank_customer.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f73aedd85ee0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bank_customer.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'bank_customer.csv' does not exist: b'bank_customer.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('bank_customer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df #  실행시 전체 dataSet 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> 불러온 csv파일 확인 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()\n",
    "# df.index()  # indext에 대한 세부정보 (! 기본RangeIndex는 안됨)  \n",
    "# df.columns  # columns 세부정보\n",
    "# df.values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> 9개의 column(index 제외) , column별 row, null값 여부, dataType 확인 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(10)  #  맨위에서 부터 10개 출력 \n",
    "# df.tail(10)  # 맨아래에서 부터 10개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T # 데이터 전치 ( Columns <-> index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(ascending=True) # ascending = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> 데이터 오름차순,내림차순 정렬 (index 기준) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='age',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> 데이터 값 기준으로 정렬(특정 column 선택) <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Selection\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df['age'] \n",
    "df[['age','cid']]  # 다중선택 => [[]]\n",
    "\n",
    "# df.loc[[0,10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> column 선택하기\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:10] # 0~9 행 슬라이스  ## df.loc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 슬라이스 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[20130101 : 20150202] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> range index뿐만 아니라 날짜 인덱스 등 다양한 형식 가능 <br>\n",
    "> 만약 index가 2013-05-02 인 경우 pandas에서 자동으로 20130502로 인식\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "####  2.1 loc,iloc\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> dataframe.loc[행,열] <br><br>\n",
    "loc[] 에 값을 하나만 넣는 경우 row 선택 <br>\n",
    "<br>\n",
    "> iloc는 정수형으로(몇번째부터 몇번째)으로 접근가능하지만 loc는 index가 정수형이 아닌경우(특정값 ex) 20130102 )인 경우를 고려해주어야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[3]        # index의 \"값\"이 3인 row의 값들을 선택\n",
    "# df.loc[0:3]      # index의 \"값\" 슬라이싱\n",
    "df.loc[[0,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.age >300  # 블리언 타입 출력\n",
    "df.loc[ df.age > 300 ]   # boolean 활용 loc 슬라이싱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> boolean값 활용 indexing <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_index(df):\n",
    "    return df.age > 300  # age 300 이상 블리언 판별 함수\n",
    "\n",
    "df.loc[re_index(df)]  #  loc의 행을 함수값으로 줌  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 함수 활용 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.loc[:,['cid','age','job']]  #  loc [행 전체 , 컬럼 사용자지정]\n",
    "\n",
    "df.loc[35:45,['age','cid']]  # loc [35~45 행, 컬럼 사용자 지정]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:10,1]   # iloc 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> iloc <br>\n",
    "> iloc는 loc와 다르게 integer 타입으로만 범위 지정이 가능하다 <br>\n",
    "> loc처럼 특정 값의 형식으로 index를 지정할 수 없고 오직 몇번째인지 integer형식으로만 지정 가능\n",
    "> df.iloc[row index range , column range]\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Setting\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임에 새로운 col을 추가할 경우 index range에 맞게 값 지정해주는 방법\n",
    "\n",
    "df_2 = df # 복사본 생성\n",
    "# df_2['E'] = df['cid']  # df_2[E] 컬럼을 원본읜 cid컬럼 가져와서 생성 (* 행범위 맞추기 위해)\n",
    "# 이런식으로 만들면 이미 만들어져 있는(범위에 맞게) 컬럼만 사용가능\n",
    "\n",
    "\n",
    "df_2.loc[:,'E'] = np.array([5] * len(df_2))  # df_2의 E컬럼선택후 np.array로 df_2의 len만큼 5 지정\n",
    "df_2.loc[0:10,['E']]  ## 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  df2 = df.copy()\n",
    "#  df2[df2 > 0] = -df2  \n",
    "#  df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "###  4. Missing Data(결측치)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 결측값 확인하기\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isnull() # 실행시 전체 dataset 결측값 여부 true / false 형식으로 반환    # notnull 은 반대로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()  # 컬럼별 결측값 개수 확인 \n",
    "\n",
    "# 결측치 갯수 파악하고자 할 경우 count 사용하면 안됨 , count는 결측값 상관안하고 행의 갯수를 반환함\n",
    "\n",
    "# df.notnull().sum()  # 컬럼별 결측값을 제외한 값의 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education'].isnull().sum()   # 특정컬럼 결측값 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum(1)  # row 별 결측값 개수 확인\n",
    "\n",
    "# df.notnull().sum(1)  # row 별 결측값 제외 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "> 결측값 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_3 = df  #  복사본 생성\n",
    "# df_3.fillna(value=5)  # 모든 결측값을 5로 대체\n",
    "# df_3.filna(value=\"string\")  # 모든 결측값을 missing라는 str값으로 대체 \n",
    "\n",
    "# df_4 = df\n",
    "# df_4.dropna(how='any')  # 결측값을 가지고 있는 모든 행 제거\n",
    "\n",
    "# df_5 = df\n",
    "# df_5.isna()   # 데이터프레임의 모든 값을 boolean 형태로 표시하고 결측값만 True값으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 결측값 연산시 <br>\n",
    "\n",
    "1. sum, comsum 연산시 => 0으로 처리 <br> \n",
    "2. mean, std 연산시 => 분석대상에서 제외 <br>\n",
    "3. column간 연산시 하나라도 결측값이면 결측값으로 반환됨 ( ex) 컬럼1 + 컬럼2 = 컬럼3 으로 표현하는 경우) <br>\n",
    "4. dataframe간 연산시 동일한 컬럼끼리는 non을 0으로 처리, 한쪽에만 존재하는 컬럼과의 연산은 non 반환\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 결측값을 가진 행만 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.loc[(train.isnull().sum(1) >= 1) , : ]\n",
    "\n",
    "# loc [ 행, 열]\n",
    "# df.isnull().sum(1) => 행기준, 결측값 개수\n",
    "# df.isnull().sum(1) >= 1      => 행기준 결측값 개수가 1보다 큰 행들\n",
    "\n",
    "# 즉, 결측값을 1개 이상 갖고있는 행들만 반환 (모든 열에 대하여)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply로 함수 적용\n",
    "\n",
    "<br>\n",
    "\n",
    "> 인자를 여러개 받을 경우 => apply 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5['age'].iloc[:10].apply(np.cumsum)   # np.cumsum함수를 apply 사용하여 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.DataFrame({'A' : [1,2,3,4],\n",
    "                    'C' : pd.Series(1,index=list(range(4)),dtype='float32') })\n",
    "\n",
    "df_t # testDF 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t[['A','C']].apply(lambda x: x.max()-x.min(), axis = 0 )  # axis=0 =>  column 기준 함수연산\n",
    "df_t[['A','C']].apply(lambda x: x.max()-x.min(), axis = 1 )  # axis=1 => row별 함수연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "##### lambda  \n",
    "\n",
    "<br>\n",
    "\n",
    ">'익명함수'를 뜻하며, 변수에 할당하지 않고 사용한다 <br>\n",
    "> 함수를 간단하게 사용할 수 있음\n",
    "\n",
    "<br>\n",
    "\n",
    "* lambda 인자 : 표현식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  hap 함수정의 \n",
    "def hap(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hap함수를 lambda로\n",
    "(lambda x,y: x + y)(10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인자를 넣지 않은 경우 \n",
    "# lambda : 0  => 모든 인자를 0으로 바꾼다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### map\n",
    "<br>\n",
    "> map(함수,리스트) <br>\n",
    "> map은 함수와 리스트를 인자로 받은후, 리스트로부터 하나씩 값을 꺼내 함수를 적용시킨 후 새로운 리스트에 결과값을 담는다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. lambda 함수 생성\n",
    "lambda x : x**2\n",
    "\n",
    "# 2. map 함수 생성 => map(함수,리스트)  ## range(5) => [0,1,2,3,4] 리스트 반환\n",
    "map(lambda x:x**2,range(5))\n",
    "\n",
    "# 3. map함수의 결과를 새로운 list에 담아냄\n",
    "list(map(lambda x : x**2,range(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### reduce\n",
    "<br>\n",
    "> reduce는 *순서형자료(리스트,튜플,문자열)의 원소들을 누적적으로 함수에 적용시켜 줌 <br>\n",
    "> reduce(함수,순서형자료)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import reduce  # reduce import\n",
    "\n",
    "reduce(lambda x,y : x+y , range(5))\n",
    "# reduce(lambda x,y : x+y , [0,1,2,3,4])\n",
    "# reduce(lambda x,y : x+y , \"안녕하세요\")\n",
    "# reduce(lambda x,y : x+y , (3,4,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### filter\n",
    "<br>\n",
    "\n",
    "> filter(함수,리스트) <br>\n",
    "> 리스트에서 함수의 조건에 참인값들을 걸러 새로운 리스트에 담아냄 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda x : x>5 ,range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda x : x, [-1,-2,0,1,2,3,4]))  # 0은 F값이므로 걸러짐 즉, 0이 되는것을 함수에 의해 0(Flase)가 되는것을 filterling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "###  5. GROUPING\n",
    "<br><br>\n",
    "\n",
    "<br>\n",
    "\n",
    "> 몇몇 기준에 따라 여러 그룹으로 데이터를 분할 (splitting) <br>\n",
    "> 각 그룹에 독립적으로 함수를 적용 (applying) <br>\n",
    "> 결과물들을 하나의 데이터 구조로 결합 (combining) <br>\n",
    "<br> \n",
    "\n",
    "> 통계량을 계산할 열.groupby(기준 열)\n",
    "> 지정한 \"그룹\"별로 통계량 측정 위해 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## job 기준 groupby\n",
    "df_grouped_job = df.groupby(df['job']).max()\n",
    "df_grouped_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  job컬럼 기준 balance 평균\n",
    "df_grouped_job_balance = df['balance'].groupby(df['job']).mean()\n",
    "df_grouped_job_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## job,marital(2개 컬럼) 기준 balance 평균 \n",
    "df_grouped_job_marital = df['balance'].groupby([df['job'],df['marital']]).mean()\n",
    "df_grouped_job_marital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹화 - '선별' 단위로 각각의 노선에 대한 총 갯수\n",
    "tmp1 = df.groupby(df['선별'])['선별'].count() # 선별 갯수만 보고싶은경우\n",
    "tmp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  transfomr 메서드\n",
    "#  groupby의 transform 메서드를 사용해 그룹에 대한 대표값을 만드는것이 아닌 그룹별 계산을 통해 데이터 자체를 변형한다\n",
    "\n",
    "# 예제\n",
    "#  df = pd.DataFrame({'group_1': ['a', 'a', 'a', 'a', 'a',  \n",
    "\n",
    "#                                   'b', 'b', 'b', 'b', 'b',], \n",
    "\n",
    "#                        'group_2': ['c', 'c', 'c', 'd', 'd', \n",
    "\n",
    "#                                      'e', 'e', 'e', 'f', 'f'], \n",
    "\n",
    "#                        'col': [1, 2, np.NaN, 4, np.NaN, \n",
    "\n",
    "#                               6, 7, np.NaN, 9, 10]})\n",
    "\n",
    "# df['nn'] = df.groupby(['group_1','group_2'])['col'].transform('max') \n",
    "# grouped된 그룹에서 가장 큰 값으로 새로 만들 컬럼('nn')의 값을 채움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 6. Categorical Data\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 data로 변환하기\n",
    "df_category = pd.DataFrame({\"id\":[1,2,3,4,5,6], \"raw_grade\":['a', 'b', 'b', 'a', 'a', 'e']})\n",
    "df_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_category.info()  # dataset 확인\n",
    "\n",
    "# 카테고리형으로 변환\n",
    "df_category['grade'] = df_category['raw_grade'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 카테고리 이름 변경\n",
    "# Series.cat.categories\n",
    "df_category['grade'].cat.categories = [\"very good\", \"good\", \"very bad\"]\n",
    "\n",
    "df_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 7. 컬럼 항목별 갯수 \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_category.groupby(df_category['grade']).size()\n",
    "\n",
    "# diamonds['cut'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 8. 자료형 변환\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object to float\n",
    "# pd.to_numeric(df_1['avg'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 9. 조건에 따라 값 변경하기 => np.where\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = numpy.where( 조건문, true일 경우 변경 값, false일 경우 변경 값 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 10. 컬럼별 데이터 조건 추출 \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df[df['E'].isin(['two', 'four'])]) # 'E'열에서 'two', 'four'을 가지고 있는 행 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 11. len VS count\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len의 경우 컬럼의 행 갯수 (nan값 포함)\n",
    "# len(df.type_of_business)\n",
    "\n",
    "\n",
    "# count의 경우 nan값을 제외한 행 갯수를 알려줌\n",
    "# df['type_of_business'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### colum명이 첫번째 데이터로 들어가있는 경우\n",
    "<br><br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./data/pima-indians-diabetes.csv', names=['pregnant','plasma','pressure','thickness',\n",
    "#                                                                'insulin','BMI','pedigree','age','diabetes'])\n",
    "\n",
    "# 이런식으로 데이터 불러옴과 동시에 column 이름 지정해주어서 해결가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### agg 사용 컬럼별 함수적용\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    groupby().agg()\n",
    "\n",
    "    DataFrame의 groupby()는 SQL의 group by 보다 유연성이 떨어질 수 밖에 없다\n",
    "    그래도 DataFrame의 groupby()에서 여러 개의 컬럼에 각각 다른 집계 함수를 사용할 때 agg() 함수 이용\n",
    "\"\"\"\n",
    "\n",
    "#  선실등급별 가장 많은 나이값, 평균요금 구하고자 한다면??\n",
    "agg_format = {'Age':'max', 'SibSp':'sum', 'Fare':'mean'} # Age 컬럼에 max함수 , SibSp 컬럼에 sum함수 Fare 컬럼에 mean 함수적용하요 groupby\n",
    "\n",
    "titanic.groupby('Pclass').agg(agg_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### agg 사용 시각화\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차종별, 노선별별 그룹화 작업\n",
    "# tmp2 = df.groupby([df['차종'],df['선별']])['총이용인원'].count() \n",
    "# tmp2\n",
    "# tmp2.plot(kind='bar',figsize=(12, 5),title=\"노선,차종별 총 이용인원\")\n",
    "\n",
    "## 위의 경우 이상하게 나옴\n",
    "\n",
    "agg_format = {'총이용인원':\"sum\", \"이용율\" : \"mean\"} # 컬럼별 함수를 다르게 지정하여 # 컬럼별 비율이 다른 경우가 많음(%,수 등등)\n",
    "\n",
    "tmp2 = df.groupby(df['선별'])[['총이용인원','이용율']].agg(agg_format) # 적용\n",
    "tmp2\n",
    "tmp2.plot(kind='bar',figsize=(12, 5),title=\"노선별 정보\",y=[\"총이용인원\",\"이용율\"],subplots=True) # subplots=True => y에 따른 그래프 각 각 생성 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 불필요한 행 제거하고 불러오기\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmaes 지정해서 불러오는 경우 기존에 있던 컬럼명이 row로 들어가버리는 경우 발생\n",
    "# 불필요한 행 제외하고 로딩하기\n",
    "# df1 = pd.read_csv(\"result/temp.csv\", names=['번호','시도','구군','인구수','넓이'],skiprows=[0],index_col='번호') # skiprows[0] 사용하여 해결"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### Json파일 불러오기\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON 파일 읽어오기\n",
    "import json\n",
    "\n",
    "df4 = json.load(open('data/JsonData.json'))\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 데이타가 많은 경우 NaN 확인하는 방법 - missngno\n",
    "<br>\n",
    "\n",
    "https://github.com/ResidentMario/missingno\n",
    "\n",
    "라이브러리 설치 (Anaconda Prompt 관리자 권한으로 실행)\n",
    " - > conda install missingno (안됨)\n",
    " - > pip install missingno (됨)\n",
    "\n",
    "Jupyter에서 바로 실행\n",
    " - > !pip install missingno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 컬럼 DateTime형식으로 변경하기\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime 오브젝트로 변경하여 필요한 데이타 추출 및 계산 - 2\n",
    "\n",
    "ebola['Date'] = pd.to_datetime(ebola['Date'])\n",
    "ebola.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### [양적자료를 질적자료로 새로 생성 ]\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.cut 함수사용하여 양적자료를 범주형자료로 ( 조건을 지정 가능)\n",
    "\n",
    "# bins에 의해서 구간 나눠서 라벨링\n",
    "# diamonds['gprice'] = pd.cut(diamonds['price'],bins=[0,5000,10000,20000], labels=['5000','10000','15000','20000'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "### 최대 출력 수 늘리기\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 판다스 데이터프레임(DataFrame)을 출력할 때, 최대 출력할 수 있는 컬럼을 100개로 늘려줍니다.\n",
    "# # 이렇게 해야 데이터를 분석할 때 출력해서 확인하기 편합니다.\n",
    "# pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "### enumerate\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx,answer in enumerate(label):\n",
    "#     p = pre[idx]\n",
    "#     if p == answer: ok+=1\n",
    "#     total +=1\n",
    "\n",
    "# enumerate 사용 시 idx에 index를 반환하는 동시에 answer에 인자의 값(여기서는 label)을 순서대로 반환 \n",
    "# 즉, 인자와 인자의 index를 동시에 사용가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "### index 바꾸기\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.set_index('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 결측값 채우기\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://rfriend.tistory.com/264"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### np.linespace 값 기준 분할\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = np.linespace(min(df['price']),max(df['price']),4)\n",
    "# group_names = ['Low','Medium','High']\n",
    "# df['price-binned'] = pd.cut(df['price'],bins,labels=group_names,include_lowtest=True)\n",
    "\n",
    "\n",
    "## bins => 바이닝 조건지정, np.linespace(최소,최대,분할그룹개수)\n",
    "## group_names => 분할그룹 라벨링\n",
    "## pd.cut 이용 데이터 바이닝\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 경고 메세지 무시하기\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### DataFrame 내 numeric(or 특정 타입) 데이터만 추출\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "# df._get_numeric_data()\n",
    "\n",
    "# 2. \n",
    "# df.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### sort와 sorted\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sorted vs sort\n",
    "    * sorted => 기존의 값을 유지하면서 정렬된값을 반환\n",
    "        * sorted.list(리스트A)\n",
    "        * 리스트A는 그대로 유지하면서 정렬된 리스트를 반환\n",
    "    * sort => 기존리스트를 정렬\n",
    "        * listA.sort()\n",
    "        * listA가 정렬되어있음\n",
    "        * 반환이 NONE이기 때문에 다른 변수로 받아도 NONE임 (ex tmp = listA.sort()의 겨우 tmp는 NONE)\n",
    "        \n",
    "    <br>\n",
    "    \n",
    "    * key parameter\n",
    "        * sorted와 sort 모두 비교를 위한 key 파라미터를 가짐\n",
    "        * 함수여야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(\"This is a test string from Andrew\".split(), key=str.lower)\n",
    "# ['a', 'Andrew', 'from', 'is', 'string', 'test', 'This']\n",
    "\n",
    "\n",
    "\n",
    "# student_tuples = [\n",
    "#     ('john', 'A', 15),\n",
    "#     ('jane', 'B', 12),\n",
    "#     ('dave', 'B', 10),\n",
    "#     ]\n",
    "# sorted(student_tuples, key=lambda student: student[2])   # sort by age\n",
    "# [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 결측값 다른값으로 변경 replace\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.replace(\"대상\",\"바꿀값\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 데이터프레임을 ndarray로 to_records()\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'A': [1, 2], 'B': [0.5, 0.75]},\n",
    "#                    index=['a', 'b'])\n",
    "\n",
    "## 출력\n",
    "# rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
    "#           dtype=[('index', 'O'), ('A', '<i8'), ('B', '<f8')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### ~ 이용하여 DataFrame에서 특정 정보 제거하기\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pos = df_pos.loc[~df_pos.index.isin(matched_row.index), :]\n",
    "\n",
    "# ~이용\n",
    "# isin => 열이 list의 값들을 포함하고 있는 모든 행들을 골라낼 때 주로 쓰인다.\n",
    "## df_pos의 인덱스 중 matched_row의 index에 포함하는값들이 있는가 단, ~가 붙어있으므로 제거됨\n",
    "# 사용코드 => 상점매상예측-guide_practice 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 결측치 시각화 missingno 라이브러리\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import missingno as msno\n",
    "\n",
    "# msno.matrix(df)  => 행,열 전체시각화\n",
    "\n",
    "# msno.bar(df) => col별 결측치 시각화\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 한글폰트\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 그래프 한글 폰트 패치\n",
    "# import platform\n",
    "# path = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "# from matplotlib import font_manager, rc\n",
    "\n",
    "# if platform.system() == \"Darwin\":\n",
    "#     rc('font',family='AppleGothic')\n",
    "# elif platform.system() == 'Windows':\n",
    "#     font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "#     rc('font',family=font_name)\n",
    "# else:\n",
    "#     print('Unknown system')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
